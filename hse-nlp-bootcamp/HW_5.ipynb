{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: textblob in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: regex in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.10.15)\n",
      "Requirement already satisfied: click in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.50.2)\n",
      "Requirement already satisfied: joblib in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.17.0)\n",
      "Requirement already satisfied: pyaspeller in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pyaspeller) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (1.25.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2.10)\n",
      "Requirement already satisfied: deep_translator in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (1.9.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from deep_translator) (4.9.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from deep_translator) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.25.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksandrakozevnikova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "!pip install pymorphy2\n",
    "!pip install textblob\n",
    "!pip install pyaspeller\n",
    "!pip install deep_translator\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from textblob import TextBlob\n",
    "from pyaspeller import YandexSpeller\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('new_test_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.02.2017 16:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.12.2016 1:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "0         ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1  fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "\n",
       "               date  \n",
       "0  16.02.2017 16:10  \n",
       "1   13.12.2016 1:05  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date'] = pd.to_datetime(train_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-12-03 23:36:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2005-01-07 16:19:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    27739\n",
       "5.0    14227\n",
       "2.0     5634\n",
       "3.0     2356\n",
       "4.0     1520\n",
       "Name: grades, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.grades.value_counts()# / train_df[train_df.grades >= 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pochtabank</td>\n",
       "      <td>Брала кредит на стиральную машину. Все платила...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-04 17:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>otpbank</td>\n",
       "      <td>Откуда взялся долг по кредитной карте, если я ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 13:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Уважаемый Бинбанк, если у вас имеются какие-ли...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-31 16:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74981</th>\n",
       "      <td>vtb</td>\n",
       "      <td>13 августа 2018 г. в ДО ЦИК «Каретный Ряд» под...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-09 14:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74984</th>\n",
       "      <td>vozrozhdenie</td>\n",
       "      <td>Обман со стороны банка. При снятии наличности ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-02 21:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74985</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Здравствуйте! По действующему ипотечному креди...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-23 11:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74988</th>\n",
       "      <td>rsb</td>\n",
       "      <td>Впервые сталкиваюсь с такой ситуацией, когда б...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-18 13:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74993</th>\n",
       "      <td>otpbank</td>\n",
       "      <td>28.03.2011 г. вечером получила письмо от Долго...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-05-04 15:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bank                                              feeds  \\\n",
       "2            alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...   \n",
       "3                 vtb  Обращаюсь к Вам с жалобой на незаконное списан...   \n",
       "5          pochtabank  Брала кредит на стиральную машину. Все платила...   \n",
       "6             otpbank  Откуда взялся долг по кредитной карте, если я ...   \n",
       "9         fk_otkritie  Уважаемый Бинбанк, если у вас имеются какие-ли...   \n",
       "...               ...                                                ...   \n",
       "74981             vtb  13 августа 2018 г. в ДО ЦИК «Каретный Ряд» под...   \n",
       "74984    vozrozhdenie  Обман со стороны банка. При снятии наличности ...   \n",
       "74985  v-express-bank  Здравствуйте! По действующему ипотечному креди...   \n",
       "74988             rsb  Впервые сталкиваюсь с такой ситуацией, когда б...   \n",
       "74993         otpbank  28.03.2011 г. вечером получила письмо от Долго...   \n",
       "\n",
       "       grades                date  \n",
       "2         NaN 2019-06-28 13:54:00  \n",
       "3         NaN 2020-07-15 14:54:00  \n",
       "5         NaN 2015-09-04 17:19:00  \n",
       "6         NaN 2021-01-28 13:20:00  \n",
       "9         NaN 2018-08-31 16:48:00  \n",
       "...       ...                 ...  \n",
       "74981     NaN 2018-05-09 14:09:00  \n",
       "74984     NaN 2013-10-02 21:46:00  \n",
       "74985     NaN 2020-06-23 11:26:00  \n",
       "74988     NaN 2015-06-18 13:34:00  \n",
       "74993     NaN 2011-05-04 15:35:00  \n",
       "\n",
       "[23524 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.grades.isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>01.07.2020 10:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>20.06.2019 13:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>20.02.2016 11:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>06.05.2019 15:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>23.05.2016 15:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "               date  \n",
       "0  01.07.2020 10:53  \n",
       "1  20.06.2019 13:19  \n",
       "2  20.02.2016 11:46  \n",
       "3  06.05.2019 15:48  \n",
       "4  23.05.2016 15:41  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начнем с предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_our = ['а', 'более', \n",
    "                 'больше', 'будет',\n",
    "                 'будто', 'бы',\n",
    "                 'был', 'была',\n",
    "                 'были', 'было',\n",
    "                 'быть', 'вдруг',\n",
    "                 'во', 'впрочем',\n",
    "                 'все', 'всегда',\n",
    "                 'всего', 'всех',\n",
    "                 'всю', 'г', 'где',\n",
    "                 'для', 'до', 'другой',\n",
    "                 'если','есть',\n",
    "                 'еще', 'ж',\n",
    "                 'же', 'за',\n",
    "                 'зачем','из',\n",
    "                 'или', 'иногда',\n",
    "                 'к', 'когда',\n",
    "                 'куда', 'между',\n",
    "                 'много', 'над',\n",
    "                 'нибудь', 'о',\n",
    "                 'об', 'от', 'перед',\n",
    "                 'по',  'под',\n",
    "                 'после', 'потом',\n",
    "                 'почти', 'при',\n",
    "                 'про', 'разве', 'с',\n",
    "                 'сейчас', 'со',\n",
    "                 'тем', 'то', 'только',\n",
    "                 'том', 'у', 'уж',\n",
    "                 'уже', 'хоть',\n",
    "                 'чем', 'чтобы',\n",
    "                 'чуть', 'я', 'и']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Исправление орфографических ошибок**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день, уважаемые сотрудники службы контроля качества данного \" замечательного \" банка. Когда же решится сой вопрос с моей кредитной картой? Ранее была выдана мне информация неким сотрудником службы контроля качества Вадимом М., что карта моя выпущена 30.01.2015 года и направлена мне. Далее поступила информация от некого сотрудника также службы контроля качества Козырева Эльдара, который мне сообщил, что карта моя перевыпущена уже 13.01.2016 года и в течении месяца должна быть доставлена мне. Сегодня уже 20. 02.2016 год. Вам самим не смешно без конца просто отписываться мне и кормить завтраками? Когда будет решён мой вопрос? Я воспользуюсь возможность и оставлю претензию на сайте ЦБ Росии о деятельности вашего банка.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speller = YandexSpeller()\n",
    "text = test_df.feeds[2]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день, уважаемые сотрудники службы контроля качества данного \" замечательного \" банка. Когда of решится сой вопрос с моей кредитной картой? Ранее была выдана мне информация неким сотрудником службы контроля качества Вадимом М., что карта моя выпущена 30.01.2015 года и направлена мне. Далее поступила информация of некого сотрудника также службы контроля качества Козырева Эльдара, который мне сообщил, что карта моя перевыпущена уже 13.01.2016 года и в течении месяца должна быть доставлена мне. Сегодня уже 20. 02.2016 год. Вам самим of смешно без конца просто отписываться мне и кормить завтраками? Когда будет решён мой вопрос? Я воспользуюсь возможность и оставлю претензию of сайте of Росии о деятельности вашего банка.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(TextBlob(text).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день, уважаемые сотрудники службы контроля качества данного \" замечательного \" банка. Когда же решится свой вопрос с моей кредитной картой? Ранее была выдана мне информация неким сотрудником службы контроля качества Вадимом М., что карта моя выпущена 30.01.2015 года и направлена мне. Далее поступила информация от некого сотрудника также службы контроля качества Козырева Эльдара, который мне сообщил, что карта моя перевыпущена уже 13.01.2016 года и в течении месяца должна быть доставлена мне. Сегодня уже 20. 02.2016 год. Вам самим не смешно без конца просто отписываться мне и кормить завтраками? Когда будет решён мой вопрос? Я воспользуюсь возможность и оставлю претензию на сайте ЦБ России о деятельности вашего банка.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed = speller.spelled(text)\n",
    "fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "Yandex Speller работает лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS = {'?' : 'вопрос',\n",
    "          '!' : 'восклицание'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_text_new(texts):\n",
    "    speller = YandexSpeller()\n",
    "    stop_words = stop_words_our\n",
    "    regex = re.compile('[^a-z A-z а-я А-Я !?]')\n",
    "    regex_1 = re.compile('[^a-z а-я]')\n",
    "    \n",
    "    preprocess_texts = []\n",
    "    caps_num = []\n",
    "    caps_words = []\n",
    "    for i in tqdm(range(len(texts))):     \n",
    "        # Поиск CAPS\n",
    "        caps_counter = 0\n",
    "        upper_words = []\n",
    "        for word in texts[i].split():\n",
    "            if word.isupper():\n",
    "                caps_counter += 1\n",
    "                word = regex_1.sub(' ', word.lower())\n",
    "                if not word in stop_words:\n",
    "                    upper_words.append(word)\n",
    "        caps_num.append(caps_counter)\n",
    "        caps_words.append(' '.join(upper_words))\n",
    "        \n",
    "        # Регистр\n",
    "        text = texts[i].lower()\n",
    "        text = text.replace('ё', 'е')\n",
    "        text = text.replace('-', '')\n",
    "        \n",
    "        #Удаление веб-адресов:\n",
    "        text = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \"сайт\", text).split())\n",
    "        text = ' '.join(re.sub(r'httpS+', \"сайт\", text).split())\n",
    "        \n",
    "        #Удаление хэштегов / аккаунтов\n",
    "        text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", text).split())\n",
    "        \n",
    "        # исправление слов с ошибками\n",
    "        text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
    "        \n",
    "        # Иставляем только нужные символы\n",
    "        text = regex.sub(' ', text)\n",
    "        \n",
    "        # исправление орфографических ошибок\n",
    "        try:\n",
    "            text = speller.spelled(text)\n",
    "        except:\n",
    "            text = str(TextBlob(text).correct())\n",
    "        \n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        \n",
    "        # заменим знаки препинания\n",
    "        prep = ' '.join([POINTS[word] if word in POINTS else word for word in filtered_sentence])\n",
    "                \n",
    "        preprocess_texts.append(prep)\n",
    "    return preprocess_texts, caps_num, caps_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75000/75000 [5:08:08<00:00,  4.06it/s]    \n"
     ]
    }
   ],
   "source": [
    "# запустим предобработку\n",
    "train_df['prep_feeds'], train_df['cups_num'], train_df['cups_words'] = prep_text_new(train_df.feeds.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('prep_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17220/17220 [1:23:03<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['prep_feeds'], test_df['cups_num'], test_df['cups_words'] = prep_text_new(test_df.feeds.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('prep_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('prep_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('prep_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "0         ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1  fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "\n",
       "   cups_num                                    cups_words  \n",
       "0         7  отвратительное отношение клиентам  ой  ужас   \n",
       "1         3                                       г  в ао  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Стемминг**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_texts(texts):\n",
    "    st = SnowballStemmer(\"russian\")\n",
    "    stem_text = []\n",
    "    for text in tqdm(texts):\n",
    "        word_tokens = word_tokenize(text)\n",
    "        stem_text.append(' '.join([st.stem(word) for word in word_tokens]))\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75000/75000 [10:31<00:00, 118.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df['stem_text'] = stemming_texts(train_df.prep_feeds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('stem_prep_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17220/17220 [02:24<00:00, 118.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['stem_text'] = stemming_texts(test_df.prep_feeds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('stem_prep_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>лет явля клиент эт банк но последн виз прост о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>ростовнадон ул ленин час в дан офис не оказа н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "      <td>здравств восклицан ран оставля отз ваш банк не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "      <td>обраща вам жалоб на незакон списан денежн сред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>им потребительск кред взят в связьбанк перешед...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank                                              feeds  grades  \\\n",
       "0           ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1    fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "2       alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     NaN   \n",
       "3            vtb  Обращаюсь к Вам с жалобой на незаконное списан...     NaN   \n",
       "4  promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2  2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3  2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "4  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         7       отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                            г  в ао   \n",
       "2         4                                      в но  а  фио    \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...   \n",
       "4         4                                            в в псб   \n",
       "\n",
       "                                           stem_text  \n",
       "0  лет явля клиент эт банк но последн виз прост о...  \n",
       "1  ростовнадон ул ленин час в дан офис не оказа н...  \n",
       "2  здравств восклицан ран оставля отз ваш банк не...  \n",
       "3  обраща вам жалоб на незакон списан денежн сред...  \n",
       "4  им потребительск кред взят в связьбанк перешед...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('stem_prep_train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>01.07.2020 10:53</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>оформля ипотек в сбербанк подгруж необходим до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>20.06.2019 13:19</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>кратк содержан не рекоменд брат кред в эт банк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>20.02.2016 11:46</td>\n",
       "      <td>добрый день уважаемые сотрудники службы контро...</td>\n",
       "      <td>3</td>\n",
       "      <td>м   цб</td>\n",
       "      <td>добр ден уважа сотрудник служб контрол качеств...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>06.05.2019 15:48</td>\n",
       "      <td>обращался получением карты зеленая польза сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>обраща получен карт зелен польз сотрудник сооб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>23.05.2016 15:41</td>\n",
       "      <td>обратилась в отделение банка на проспекте лени...</td>\n",
       "      <td>9</td>\n",
       "      <td>втб    втб   втб   бесплатно колоссальный боль...</td>\n",
       "      <td>обрат в отделен банк на проспект ленин в отдел...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "               date                                         prep_feeds  \\\n",
       "0  01.07.2020 10:53  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1  20.06.2019 13:19  краткое содержание не рекомендую брать кредит ...   \n",
       "2  20.02.2016 11:46  добрый день уважаемые сотрудники службы контро...   \n",
       "3  06.05.2019 15:48  обращался получением карты зеленая польза сотр...   \n",
       "4  23.05.2016 15:41  обратилась в отделение банка на проспекте лени...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         0                                                NaN   \n",
       "1         3                                              в в в   \n",
       "2         3                                             м   цб   \n",
       "3         0                                                NaN   \n",
       "4         9  втб    втб   втб   бесплатно колоссальный боль...   \n",
       "\n",
       "                                           stem_text  \n",
       "0  оформля ипотек в сбербанк подгруж необходим до...  \n",
       "1  кратк содержан не рекоменд брат кред в эт банк...  \n",
       "2  добр ден уважа сотрудник служб контрол качеств...  \n",
       "3  обраща получен карт зелен польз сотрудник сооб...  \n",
       "4  обрат в отделен банк на проспект ленин в отдел...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('stem_prep_test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем для трейна только те коменты, где есть оценка\n",
    "TRAIN_1 = train_df[train_df.notna().grades]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_2 = train_df[train_df.grades.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=81000, analyzer='word', ngram_range=(1, 1))\n",
    "vect_chars = TfidfVectorizer(max_features=27600, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_train = vect_words.fit_transform(TRAIN_1.stem_text)\n",
    "all_chars_train = vect_chars.fit_transform(TRAIN_1.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 65290)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 24988)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропуски в train\n",
    "all_words_train_2 = vect_words.transform(TRAIN_2.stem_text)\n",
    "all_chars_train_2 = vect_chars.transform(TRAIN_2.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23524, 65290)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_test = vect_words.transform(test_df.stem_text)\n",
    "all_chars_test = vect_chars.transform(test_df.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 65290)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 24988)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем матрицу признаков TF-IDF для теста и трейна\n",
    "train_feats = sparse.hstack([all_words_train, all_chars_train])\n",
    "train_2_feats = sparse.hstack([all_words_train_2, all_chars_train_2])\n",
    "test_feats = sparse.hstack([all_words_test, all_chars_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 90278)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "Возьмем LR с 5 фолдами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR_CV5 = LogisticRegressionCV(solver='saga', cv=5, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, scoring=&#x27;f1_micro&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, scoring=&#x27;f1_micro&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, scoring='f1_micro', solver='saga')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR_CV5.fit(train_feats, TRAIN_1.grades.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним модельку\n",
    "with open('model_tfidf_train_1.pickle', 'wb') as f:\n",
    "    pickle.dump(model_LR_CV5, f)\n",
    "\n",
    "with open('model_tfidf_train_1.pickle', 'rb') as f:\n",
    "    model_LR_CV5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем прогноз\n",
    "test_predicted = model_LR_CV5.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = test_predicted.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inds</th>\n",
       "      <th>grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17215</th>\n",
       "      <td>17215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17216</th>\n",
       "      <td>17216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17217</th>\n",
       "      <td>17217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17218</th>\n",
       "      <td>17218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17219</th>\n",
       "      <td>17219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        inds  grades\n",
       "0          0       1\n",
       "1          1       1\n",
       "2          2       1\n",
       "3          3       1\n",
       "4          4       1\n",
       "...      ...     ...\n",
       "17215  17215       1\n",
       "17216  17216       1\n",
       "17217  17217       1\n",
       "17218  17218       1\n",
       "17219  17219       1\n",
       "\n",
       "[17220 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = pd.DataFrame({'inds': test_df.index,\n",
    "                    'grades': test_predicted})\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.to_csv('new_baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
