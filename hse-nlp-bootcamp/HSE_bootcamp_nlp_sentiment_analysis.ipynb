{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: textblob in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: joblib in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.17.0)\n",
      "Requirement already satisfied: click in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.50.2)\n",
      "Requirement already satisfied: regex in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.10.15)\n",
      "Requirement already satisfied: pyaspeller in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pyaspeller) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2.10)\n",
      "Requirement already satisfied: deep_translator in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (1.9.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from deep_translator) (4.9.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from deep_translator) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.25.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksandrakozevnikova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "!pip install pymorphy2\n",
    "!pip install textblob\n",
    "!pip install pyaspeller\n",
    "!pip install deep_translator\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from textblob import TextBlob\n",
    "from pyaspeller import YandexSpeller\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('new_test_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.02.2017 16:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.12.2016 1:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "0         ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1  fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "\n",
       "               date  \n",
       "0  16.02.2017 16:10  \n",
       "1   13.12.2016 1:05  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date'] = pd.to_datetime(train_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-12-03 23:36:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2005-01-07 16:19:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    27739\n",
       "5.0    14227\n",
       "2.0     5634\n",
       "3.0     2356\n",
       "4.0     1520\n",
       "Name: grades, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.grades.value_counts()# / train_df[train_df.grades >= 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pochtabank</td>\n",
       "      <td>Брала кредит на стиральную машину. Все платила...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-04 17:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>otpbank</td>\n",
       "      <td>Откуда взялся долг по кредитной карте, если я ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 13:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Уважаемый Бинбанк, если у вас имеются какие-ли...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-31 16:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74981</th>\n",
       "      <td>vtb</td>\n",
       "      <td>13 августа 2018 г. в ДО ЦИК «Каретный Ряд» под...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-09 14:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74984</th>\n",
       "      <td>vozrozhdenie</td>\n",
       "      <td>Обман со стороны банка. При снятии наличности ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-02 21:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74985</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Здравствуйте! По действующему ипотечному креди...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-23 11:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74988</th>\n",
       "      <td>rsb</td>\n",
       "      <td>Впервые сталкиваюсь с такой ситуацией, когда б...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-18 13:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74993</th>\n",
       "      <td>otpbank</td>\n",
       "      <td>28.03.2011 г. вечером получила письмо от Долго...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-05-04 15:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bank                                              feeds  \\\n",
       "2            alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...   \n",
       "3                 vtb  Обращаюсь к Вам с жалобой на незаконное списан...   \n",
       "5          pochtabank  Брала кредит на стиральную машину. Все платила...   \n",
       "6             otpbank  Откуда взялся долг по кредитной карте, если я ...   \n",
       "9         fk_otkritie  Уважаемый Бинбанк, если у вас имеются какие-ли...   \n",
       "...               ...                                                ...   \n",
       "74981             vtb  13 августа 2018 г. в ДО ЦИК «Каретный Ряд» под...   \n",
       "74984    vozrozhdenie  Обман со стороны банка. При снятии наличности ...   \n",
       "74985  v-express-bank  Здравствуйте! По действующему ипотечному креди...   \n",
       "74988             rsb  Впервые сталкиваюсь с такой ситуацией, когда б...   \n",
       "74993         otpbank  28.03.2011 г. вечером получила письмо от Долго...   \n",
       "\n",
       "       grades                date  \n",
       "2         NaN 2019-06-28 13:54:00  \n",
       "3         NaN 2020-07-15 14:54:00  \n",
       "5         NaN 2015-09-04 17:19:00  \n",
       "6         NaN 2021-01-28 13:20:00  \n",
       "9         NaN 2018-08-31 16:48:00  \n",
       "...       ...                 ...  \n",
       "74981     NaN 2018-05-09 14:09:00  \n",
       "74984     NaN 2013-10-02 21:46:00  \n",
       "74985     NaN 2020-06-23 11:26:00  \n",
       "74988     NaN 2015-06-18 13:34:00  \n",
       "74993     NaN 2011-05-04 15:35:00  \n",
       "\n",
       "[23524 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.grades.isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>01.07.2020 10:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>20.06.2019 13:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>20.02.2016 11:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>06.05.2019 15:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>23.05.2016 15:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "               date  \n",
       "0  01.07.2020 10:53  \n",
       "1  20.06.2019 13:19  \n",
       "2  20.02.2016 11:46  \n",
       "3  06.05.2019 15:48  \n",
       "4  23.05.2016 15:41  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начнем с предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[:1000].to_excel('train.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_our = ['а', 'более', \n",
    "                 'больше', 'будет',\n",
    "                 'будто', 'бы',\n",
    "                 'был', 'была',\n",
    "                 'были', 'было',\n",
    "                 'быть', 'вдруг',\n",
    "                 'во', 'впрочем',\n",
    "                 'все', 'всегда',\n",
    "                 'всего', 'всех',\n",
    "                 'всю', 'г', 'где',\n",
    "                 'для', 'до', 'другой',\n",
    "                 'если','есть',\n",
    "                 'еще', 'ж',\n",
    "                 'же', 'за',\n",
    "                 'зачем','из',\n",
    "                 'или', 'иногда',\n",
    "                 'к', 'когда',\n",
    "                 'куда', 'между',\n",
    "                 'много', 'над',\n",
    "                 'нибудь', 'о',\n",
    "                 'об', 'от', 'перед',\n",
    "                 'по',  'под',\n",
    "                 'после', 'потом',\n",
    "                 'почти', 'при',\n",
    "                 'про', 'разве', 'с',\n",
    "                 'сейчас', 'со',\n",
    "                 'тем', 'то', 'только',\n",
    "                 'том', 'у', 'уж',\n",
    "                 'уже', 'хоть',\n",
    "                 'чем', 'чтобы',\n",
    "                 'чуть', 'я', 'и']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Исправление орфографических ошибок**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день, уважаемые сотрудники службы контроля качества данного \" замечательного \" банка. Когда же решится сой вопрос с моей кредитной картой? Ранее была выдана мне информация неким сотрудником службы контроля качества Вадимом М., что карта моя выпущена 30.01.2015 года и направлена мне. Далее поступила информация от некого сотрудника также службы контроля качества Козырева Эльдара, который мне сообщил, что карта моя перевыпущена уже 13.01.2016 года и в течении месяца должна быть доставлена мне. Сегодня уже 20. 02.2016 год. Вам самим не смешно без конца просто отписываться мне и кормить завтраками? Когда будет решён мой вопрос? Я воспользуюсь возможность и оставлю претензию на сайте ЦБ Росии о деятельности вашего банка.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speller = YandexSpeller()\n",
    "text = test_df.feeds[2]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день, уважаемые сотрудники службы контроля качества данного \" замечательного \" банка. Когда of решится сой вопрос с моей кредитной картой? Ранее была выдана мне информация неким сотрудником службы контроля качества Вадимом М., что карта моя выпущена 30.01.2015 года и направлена мне. Далее поступила информация of некого сотрудника также службы контроля качества Козырева Эльдара, который мне сообщил, что карта моя перевыпущена уже 13.01.2016 года и в течении месяца должна быть доставлена мне. Сегодня уже 20. 02.2016 год. Вам самим of смешно без конца просто отписываться мне и кормить завтраками? Когда будет решён мой вопрос? Я воспользуюсь возможность и оставлю претензию of сайте of Росии о деятельности вашего банка.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(TextBlob(text).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Добрый день, уважаемые сотрудники службы контроля качества данного \" замечательного \" банка. Когда же решится свой вопрос с моей кредитной картой? Ранее была выдана мне информация неким сотрудником службы контроля качества Вадимом М., что карта моя выпущена 30.01.2015 года и направлена мне. Далее поступила информация от некого сотрудника также службы контроля качества Козырева Эльдара, который мне сообщил, что карта моя перевыпущена уже 13.01.2016 года и в течении месяца должна быть доставлена мне. Сегодня уже 20. 02.2016 год. Вам самим не смешно без конца просто отписываться мне и кормить завтраками? Когда будет решён мой вопрос? Я воспользуюсь возможность и оставлю претензию на сайте ЦБ России о деятельности вашего банка.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed = speller.spelled(text)\n",
    "fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "Yandex Speller работает лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS = {'?' : 'вопрос',\n",
    "          '!' : 'восклицание'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_text_new(texts):\n",
    "    speller = YandexSpeller()\n",
    "    stop_words = stop_words_our\n",
    "    regex = re.compile('[^a-z A-z а-я А-Я !?]')\n",
    "    regex_1 = re.compile('[^a-z а-я]')\n",
    "    \n",
    "    preprocess_texts = []\n",
    "    caps_num = []\n",
    "    caps_words = []\n",
    "    for i in tqdm(range(len(texts))):     \n",
    "        # Поиск CAPS\n",
    "        caps_counter = 0\n",
    "        upper_words = []\n",
    "        for word in texts[i].split():\n",
    "            if word.isupper():\n",
    "                caps_counter += 1\n",
    "                word = regex_1.sub(' ', word.lower())\n",
    "                if not word in stop_words:\n",
    "                    upper_words.append(word)\n",
    "        caps_num.append(caps_counter)\n",
    "        caps_words.append(' '.join(upper_words))\n",
    "        \n",
    "        # Регистр\n",
    "        text = texts[i].lower()\n",
    "        text = text.replace('ё', 'е')\n",
    "        text = text.replace('-', '')\n",
    "        \n",
    "        #Удаление веб-адресов:\n",
    "        text = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \"сайт\", text).split())\n",
    "        text = ' '.join(re.sub(r'httpS+', \"сайт\", text).split())\n",
    "        \n",
    "        #Удаление хэштегов / аккаунтов\n",
    "        text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", text).split())\n",
    "        \n",
    "        # исправление слов с ошибками\n",
    "        text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
    "        \n",
    "        # Иставляем только нужные символы\n",
    "        text = regex.sub(' ', text)\n",
    "        \n",
    "        # исправление орфографических ошибок\n",
    "        try:\n",
    "            text = speller.spelled(text)\n",
    "        except:\n",
    "            text = str(TextBlob(text).correct())\n",
    "        \n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        \n",
    "        # заменим знаки препинания\n",
    "        prep = ' '.join([POINTS[word] if word in POINTS else word for word in filtered_sentence])\n",
    "                \n",
    "        preprocess_texts.append(prep)\n",
    "    return preprocess_texts, caps_num, caps_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75000/75000 [5:08:08<00:00,  4.06it/s]    \n"
     ]
    }
   ],
   "source": [
    "# запустим предобработку\n",
    "train_df['prep_feeds'], train_df['cups_num'], train_df['cups_words'] = prep_text_new(train_df.feeds.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('prep_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17220/17220 [1:23:03<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['prep_feeds'], test_df['cups_num'], test_df['cups_words'] = prep_text_new(test_df.feeds.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('prep_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaspeller in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pyaspeller) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.27.1->pyaspeller) (1.25.11)\n",
      "Requirement already satisfied: deep_translator in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (1.9.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from deep_translator) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from deep_translator) (4.9.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.25.11)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.0.1)\n",
      "Requirement already satisfied: pymorphy2 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/aleksandrakozevnikova/opt/anaconda3/lib/python3.8/site-packages (from pymorphy2) (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaspeller\n",
    "!pip install deep_translator \n",
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksandrakozevnikova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aleksandrakozevnikova/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import itertools\n",
    "from scipy import sparse\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from textblob import TextBlob\n",
    "from pyaspeller import YandexSpeller\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('prep_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('prep_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "0         ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1  fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "\n",
       "   cups_num                                    cups_words  \n",
       "0         7  отвратительное отношение клиентам  ой  ужас   \n",
       "1         3                                       г  в ао  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_texts(texts):\n",
    "    st = SnowballStemmer(\"russian\")\n",
    "    stem_text = []\n",
    "    for text in tqdm(texts):\n",
    "        word_tokens = word_tokenize(text)\n",
    "        stem_text.append(' '.join([st.stem(word) for word in word_tokens]))\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75000/75000 [10:31<00:00, 118.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df['stem_text'] = stemming_texts(train_df.prep_feeds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('stem_prep_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17220/17220 [02:24<00:00, 118.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['stem_text'] = stemming_texts(test_df.prep_feeds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('stem_prep_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>лет явля клиент эт банк но последн виз прост о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>ростовнадон ул ленин час в дан офис не оказа н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "      <td>здравств восклицан ран оставля отз ваш банк не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "      <td>обраща вам жалоб на незакон списан денежн сред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>им потребительск кред взят в связьбанк перешед...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank                                              feeds  grades  \\\n",
       "0           ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1    fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "2       alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     NaN   \n",
       "3            vtb  Обращаюсь к Вам с жалобой на незаконное списан...     NaN   \n",
       "4  promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2  2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3  2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "4  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         7       отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                            г  в ао   \n",
       "2         4                                      в но  а  фио    \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...   \n",
       "4         4                                            в в псб   \n",
       "\n",
       "                                           stem_text  \n",
       "0  лет явля клиент эт банк но последн виз прост о...  \n",
       "1  ростовнадон ул ленин час в дан офис не оказа н...  \n",
       "2  здравств восклицан ран оставля отз ваш банк не...  \n",
       "3  обраща вам жалоб на незакон списан денежн сред...  \n",
       "4  им потребительск кред взят в связьбанк перешед...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('stem_prep_train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>01.07.2020 10:53</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>оформля ипотек в сбербанк подгруж необходим до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>20.06.2019 13:19</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>кратк содержан не рекоменд брат кред в эт банк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>20.02.2016 11:46</td>\n",
       "      <td>добрый день уважаемые сотрудники службы контро...</td>\n",
       "      <td>3</td>\n",
       "      <td>м   цб</td>\n",
       "      <td>добр ден уважа сотрудник служб контрол качеств...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>06.05.2019 15:48</td>\n",
       "      <td>обращался получением карты зеленая польза сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>обраща получен карт зелен польз сотрудник сооб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>23.05.2016 15:41</td>\n",
       "      <td>обратилась в отделение банка на проспекте лени...</td>\n",
       "      <td>9</td>\n",
       "      <td>втб    втб   втб   бесплатно колоссальный боль...</td>\n",
       "      <td>обрат в отделен банк на проспект ленин в отдел...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "               date                                         prep_feeds  \\\n",
       "0  01.07.2020 10:53  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1  20.06.2019 13:19  краткое содержание не рекомендую брать кредит ...   \n",
       "2  20.02.2016 11:46  добрый день уважаемые сотрудники службы контро...   \n",
       "3  06.05.2019 15:48  обращался получением карты зеленая польза сотр...   \n",
       "4  23.05.2016 15:41  обратилась в отделение банка на проспекте лени...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         0                                                NaN   \n",
       "1         3                                              в в в   \n",
       "2         3                                             м   цб   \n",
       "3         0                                                NaN   \n",
       "4         9  втб    втб   втб   бесплатно колоссальный боль...   \n",
       "\n",
       "                                           stem_text  \n",
       "0  оформля ипотек в сбербанк подгруж необходим до...  \n",
       "1  кратк содержан не рекоменд брат кред в эт банк...  \n",
       "2  добр ден уважа сотрудник служб контрол качеств...  \n",
       "3  обраща получен карт зелен польз сотрудник сооб...  \n",
       "4  обрат в отделен банк на проспект ленин в отдел...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('stem_prep_test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем для трейна только те коменты, где есть оценка\n",
    "TRAIN_1 = train_df[train_df.notna().grades]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_2 = train_df[train_df.grades.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=81000, analyzer='word', ngram_range=(1, 1))\n",
    "vect_chars = TfidfVectorizer(max_features=27600, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_train = vect_words.fit_transform(TRAIN_1.stem_text)\n",
    "all_chars_train = vect_chars.fit_transform(TRAIN_1.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 65290)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 24988)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропуски в train\n",
    "all_words_train_2 = vect_words.transform(TRAIN_2.stem_text)\n",
    "all_chars_train_2 = vect_chars.transform(TRAIN_2.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23524, 65290)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_test = vect_words.transform(test_df.stem_text)\n",
    "all_chars_test = vect_chars.transform(test_df.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 65290)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 24988)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем матрицу признаков TF-IDF для теста и трейна\n",
    "train_feats = sparse.hstack([all_words_train, all_chars_train])\n",
    "train_2_feats = sparse.hstack([all_words_train_2, all_chars_train_2])\n",
    "test_feats = sparse.hstack([all_words_test, all_chars_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR_CV5 = LogisticRegressionCV(solver='saga', cv=5, scoring='f1_score')\n",
    "model_LR_CV5.fit(train_feats, TRAIN_1.grades.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model_LR_CV5, train_feats, TRAIN_1.grades.values, cv=5, scoring=('f1_score'), return_train_score=True)\n",
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted = model_LR_CV5.predict(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем прогноз\n",
    "test_predicted = model_LR_CV5.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = test_predicted.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = pd.DataFrame({'inds': test_df.index,\n",
    "                    'grades': test_predicted})\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.to_csv('new_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_translate = 'I want to translate this text'\n",
    "translated = GoogleTranslator(source='auto', target='ru').translate(to_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я хочу перевести этот текст'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соберем доп данные путем перевода на английский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(x, df):\n",
    "    #result = []\n",
    "    for it in tqdm.tqdm(x):\n",
    "        try:\n",
    "            translated = GoogleTranslator(source='auto', target='en').translate(it)\n",
    "            tmp = {'comment' : translated}\n",
    "            df = df.append(tmp, ignore_index=True)\n",
    "            #result.append(translated)\n",
    "        except:\n",
    "            translated = 'miss'\n",
    "            #result.append(translated)\n",
    "            tmp = {'comment' : translated}\n",
    "            df = df.append(tmp, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [comment]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df = pd.DataFrame(columns=['comment'])\n",
    "en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 75000/75000 [14:43:03<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_EN = translate(train_df.feeds.to_list(), en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello! I have already left a review about your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am writing to you with a complaint about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have a consumer loan taken from Svyaz-Bank a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0  I have been a client of this bank for many yea...\n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...\n",
       "2  Hello! I have already left a review about your...\n",
       "3  I am writing to you with a complaint about the...\n",
       "4  I have a consumer loan taken from Svyaz-Bank a..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_EN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EN.to_csv('train_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [comment]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df = pd.DataFrame(columns=['comment'])\n",
    "en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 17220/17220 [2:57:18<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "TEST_EN = translate(test_df.feeds.to_list(), en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EN.to_csv('test_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EN = pd.read_csv('train_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello! I have already left a review about your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am writing to you with a complaint about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have a consumer loan taken from Svyaz-Bank a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0  I have been a client of this bank for many yea...\n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...\n",
       "2  Hello! I have already left a review about your...\n",
       "3  I am writing to you with a complaint about the...\n",
       "4  I have a consumer loan taken from Svyaz-Bank a..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_EN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь назад\n",
    "def translate_ru(x):\n",
    "    result = []\n",
    "    for it in tqdm(x):\n",
    "        try:\n",
    "            translated = GoogleTranslator(source='auto', target='ru').translate(it)\n",
    "            #tmp = {'comment' : translated}\n",
    "            #df = df.append(tmp, ignore_index=True)\n",
    "            result.append(translated)\n",
    "        except:\n",
    "            translated = 'miss'\n",
    "            result.append(translated)\n",
    "            #tmp = {'comment' : translated}\n",
    "            #df = df.append(tmp, ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_df = pd.DataFrame(columns=['comment'])\n",
    "#en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████▋                     | 52421/75000 [19:26:00<7:17:35,  1.16s/it]"
     ]
    }
   ],
   "source": [
    "TRAIN_EN['ru'] = translate_ru(TRAIN_EN.comment.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EN.to_csv('train_en_ru.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EN = pd.read_csv('test_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EN['ru'] = translate_ru(TEST_EN.comment.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EN.to_csv('test_en_ru.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучим модель № 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продолжим работу из colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_W_ADD = pd.read_csv('TRAIN_W_ADD_RATING.csv')\n",
    "\n",
    "test_df = pd.read_csv('test_df_RATING.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=50000, analyzer='word', ngram_range=(1, 3))\n",
    "vect_chars = TfidfVectorizer(max_features=25000, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_train = vect_words.fit_transform(TRAIN_W_ADD.stem_text)\n",
    "all_chars_train = vect_chars.fit_transform(TRAIN_W_ADD.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_test = vect_words.transform(test_df.stem_text)\n",
    "all_chars_test = vect_chars.transform(test_df.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем матрицу признаков TF-IDF для теста и трейна\n",
    "train_feats = sparse.hstack([all_words_train, all_chars_train])\n",
    "test_feats = sparse.hstack([all_words_test, all_chars_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70827, 75000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegressionCV from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('model_tfidf_BigData_3.pickle', 'rb') as f:\n",
    "    model_3_LR_CV3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на признаки\n",
    "coef = model_3_LR_CV3.coef_.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_features = train_feats.tocsr()[:, (np.abs(coef) > 1e-15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_features = test_feats.tocsr()[:, (np.abs(coef) > 1e-15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70827, 8728)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0, 1, 2])],   # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_train = ct.fit_transform(TRAIN_W_ADD.loc[:, ['bank', 'y', 'm', 'cups_num', 'rating', 'len']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70827, 101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>2020-01-07 10:53:00</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>оформля ипотек в сбербанк подгруж необходим до...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1.767017</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>2019-06-20 13:19:00</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>кратк содержан не рекоменд брат кред в эт банк...</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>1.942431</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>2016-02-20 11:46:00</td>\n",
       "      <td>добрый день уважаемые сотрудники службы контро...</td>\n",
       "      <td>3</td>\n",
       "      <td>м   цб</td>\n",
       "      <td>добр ден уважа сотрудник служб контрол качеств...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1.120879</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>2019-06-05 15:48:00</td>\n",
       "      <td>обращался получением карты зеленая польза сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>обраща получен карт зелен польз сотрудник сооб...</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2.659696</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>2016-05-23 15:41:00</td>\n",
       "      <td>обратилась в отделение банка на проспекте лени...</td>\n",
       "      <td>9</td>\n",
       "      <td>втб    втб   втб   бесплатно колоссальный боль...</td>\n",
       "      <td>обрат в отделен банк на проспект ленин в отдел...</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>1.885882</td>\n",
       "      <td>2510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2020-01-07 10:53:00  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1  2019-06-20 13:19:00  краткое содержание не рекомендую брать кредит ...   \n",
       "2  2016-02-20 11:46:00  добрый день уважаемые сотрудники службы контро...   \n",
       "3  2019-06-05 15:48:00  обращался получением карты зеленая польза сотр...   \n",
       "4  2016-05-23 15:41:00  обратилась в отделение банка на проспекте лени...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         0                                                NaN   \n",
       "1         3                                              в в в   \n",
       "2         3                                             м   цб   \n",
       "3         0                                                NaN   \n",
       "4         9  втб    втб   втб   бесплатно колоссальный боль...   \n",
       "\n",
       "                                           stem_text     y  m    rating   len  \n",
       "0  оформля ипотек в сбербанк подгруж необходим до...  2020  1  1.767017   331  \n",
       "1  кратк содержан не рекоменд брат кред в эт банк...  2019  6  1.942431  1048  \n",
       "2  добр ден уважа сотрудник служб контрол качеств...  2016  2  1.120879   731  \n",
       "3  обраща получен карт зелен польз сотрудник сооб...  2019  6  2.659696   415  \n",
       "4  обрат в отделен банк на проспект ленин в отдел...  2016  5  1.885882  2510  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_test = ct.transform(test_df.loc[:, ['bank', 'y', 'm', 'cups_num', 'rating', 'len']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Склеим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Склеим данные\n",
    "train_sparse = sparse.hstack([new_train_features, ohe_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sparse = sparse.hstack([new_test_features, ohe_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70827, 8829)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 8829)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем что-нибудь обучить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>лет явля клиент эт банк но последн виз прост о...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>ростовнадон ул ленин час в дан офис не оказа н...</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>1.652968</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>им потребительск кред взят в связьбанк перешед...</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>1.945946</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Хочу выразить глубокую благодарность всем сотр...</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-04-19 20:11:00</td>\n",
       "      <td>хочу выразить глубокую благодарность всем сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>хоч выраз глубок благодарн всем сотрудник высо...</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>1.473498</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>6 марта 2019г. В 10:33 при проходе в метро \"Ку...</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-28 18:36:00</td>\n",
       "      <td>марта в проходе в метро курская социальной кар...</td>\n",
       "      <td>3</td>\n",
       "      <td>в втб</td>\n",
       "      <td>март в проход в метр курск социальн карт беспл...</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>2.236177</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  grades  \\\n",
       "0            ubrr  Много лет являюсь клиентом этого банка, но пос...       1   \n",
       "1     fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....       2   \n",
       "2   promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...       2   \n",
       "3  homecreditbank  Хочу выразить глубокую благодарность всем сотр...       5   \n",
       "4             vtb  6 марта 2019г. В 10:33 при проходе в метро \"Ку...       2   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "3  2015-04-19 20:11:00  хочу выразить глубокую благодарность всем сотр...   \n",
       "4  2019-03-28 18:36:00  марта в проходе в метро курская социальной кар...   \n",
       "\n",
       "   cups_num                                    cups_words  \\\n",
       "0         7  отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                       г  в ао   \n",
       "2         4                                       в в псб   \n",
       "3         0                                           NaN   \n",
       "4         3                                         в втб   \n",
       "\n",
       "                                           stem_text     y   m    rating   len  \n",
       "0  лет явля клиент эт банк но последн виз прост о...  2017   2  1.421053  1286  \n",
       "1  ростовнадон ул ленин час в дан офис не оказа н...  2016  12  1.652968  1000  \n",
       "2  им потребительск кред взят в связьбанк перешед...  2020   4  1.945946  1614  \n",
       "3  хоч выраз глубок благодарн всем сотрудник высо...  2015   4  1.473498   438  \n",
       "4  март в проход в метр курск социальн карт беспл...  2019   3  2.236177  1175  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_W_ADD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "clf2 = LinearSVC()\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('svc', clf2), ('gnb', clf3)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 351, in fit\n    return super().fit(X, transformed_y, sample_weight)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 83, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 47, in _fit_single_estimator\n    estimator.fit(X, y)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 243, in fit\n    return self._partial_fit(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 400, in _partial_fit\n    X, y = self._validate_data(X, y, reset=first_call)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 822, in check_array\n    array = _ensure_sparse_format(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 512, in _ensure_sparse_format\n    raise TypeError(\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-aaceee6d883e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m scores = cross_validate(eclf1, train_sparse, TRAIN_W_ADD.grades.values, cv=3,\n\u001b[0m\u001b[0;32m      2\u001b[0m                          \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f1_micro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                          return_train_score=True)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             )\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 351, in fit\n    return super().fit(X, transformed_y, sample_weight)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 83, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 47, in _fit_single_estimator\n    estimator.fit(X, y)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 243, in fit\n    return self._partial_fit(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 400, in _partial_fit\n    X, y = self._validate_data(X, y, reset=first_call)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 822, in check_array\n    array = _ensure_sparse_format(\n  File \"C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 512, in _ensure_sparse_format\n    raise TypeError(\nTypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(eclf1, train_sparse, TRAIN_W_ADD.grades.values, cv=3,\n",
    "                         scoring=('f1_micro'),\n",
    "                         return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_LR_CV7 = LogisticRegressionCV(solver='sag', cv=7, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=7, scoring=&#x27;f1_micro&#x27;, solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=7, scoring=&#x27;f1_micro&#x27;, solver=&#x27;sag&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=7, scoring='f1_micro', solver='sag')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_LR_CV7.fit(new_train_features, TRAIN_W_ADD.grades.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_5_LR_CV7.predict(new_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644867070467477"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predicted, TRAIN_W_ADD.grades.values, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним модельку\n",
    "with open('model_5_coef_OHE.pickle', 'wb') as f:\n",
    "    pickle.dump(model_5_LR_CV7, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем прогноз\n",
    "#test_predicted = model_5_LR_CV3.predict(test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predicted = test_predicted.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sol = pd.DataFrame({'inds': test_df.index,\n",
    "#                    'grades': test_predicted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sol.to_csv('solution_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поработаем с доразметкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Неуверенные прогнозы на трейне/UNSURE_tr_2_wt_first.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsure = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Несколько лет с удовольствием пользовалась усл...</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-10 19:29:00</td>\n",
       "      <td>несколько лет удовольствием пользовалась услуг...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>нескольк лет удовольств пользова услуг эт банк...</td>\n",
       "      <td>0.452553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unicreditbank</td>\n",
       "      <td>Без оценки по причине, что так и допожно быть ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-03-25 00:35:00</td>\n",
       "      <td>без оценки причине что так допожно в нормальны...</td>\n",
       "      <td>1</td>\n",
       "      <td>в</td>\n",
       "      <td>без оценк причин что так допожн в нормальн бан...</td>\n",
       "      <td>0.447934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rsb</td>\n",
       "      <td>Был клиентом огромного кол-ва финансовых учреж...</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-02-09 11:32:00</td>\n",
       "      <td>клиентом огромного колва финансовых учреждений...</td>\n",
       "      <td>2</td>\n",
       "      <td>в в</td>\n",
       "      <td>клиент огромн колв финансов учрежден бизнес по...</td>\n",
       "      <td>0.722269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Вопрос:Добрый день! Я страдаю от тяжелой депре...</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-09-27 21:27:00</td>\n",
       "      <td>вопрос добрый день восклицание страдаю тяжелой...</td>\n",
       "      <td>7</td>\n",
       "      <td>а</td>\n",
       "      <td>вопрос добр ден восклицан страда тяжел депресс...</td>\n",
       "      <td>0.421834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avangard</td>\n",
       "      <td>Партнёрствую с Авангардом уже более 10 лет и к...</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-12 12:25:00</td>\n",
       "      <td>партнерствую авангардом лет как физ как юрлицо...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>партнерств авангард лет как физ как юрлиц стал...</td>\n",
       "      <td>0.447373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  grades  \\\n",
       "0  homecreditbank  Несколько лет с удовольствием пользовалась усл...       3   \n",
       "1   unicreditbank  Без оценки по причине, что так и допожно быть ...       5   \n",
       "2             rsb  Был клиентом огромного кол-ва финансовых учреж...       5   \n",
       "3        alfabank  Вопрос:Добрый день! Я страдаю от тяжелой депре...       3   \n",
       "4        avangard  Партнёрствую с Авангардом уже более 10 лет и к...       5   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2015-02-10 19:29:00  несколько лет удовольствием пользовалась услуг...   \n",
       "1  2014-03-25 00:35:00  без оценки причине что так допожно в нормальны...   \n",
       "2  2015-02-09 11:32:00  клиентом огромного колва финансовых учреждений...   \n",
       "3  2020-09-27 21:27:00  вопрос добрый день восклицание страдаю тяжелой...   \n",
       "4  2018-04-12 12:25:00  партнерствую авангардом лет как физ как юрлицо...   \n",
       "\n",
       "   cups_num cups_words                                          stem_text  \\\n",
       "0         0        NaN  нескольк лет удовольств пользова услуг эт банк...   \n",
       "1         1          в  без оценк причин что так допожн в нормальн бан...   \n",
       "2         2        в в  клиент огромн колв финансов учрежден бизнес по...   \n",
       "3         7         а   вопрос добр ден восклицан страда тяжел депресс...   \n",
       "4         2        NaN  партнерств авангард лет как физ как юрлиц стал...   \n",
       "\n",
       "      proba  \n",
       "0  0.452553  \n",
       "1  0.447934  \n",
       "2  0.722269  \n",
       "3  0.421834  \n",
       "4  0.447373  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Несколько лет с удовольствием пользовалась усл...</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-10 19:29:00</td>\n",
       "      <td>несколько лет удовольствием пользовалась услуг...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>нескольк лет удовольств пользова услуг эт банк...</td>\n",
       "      <td>0.452553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unicreditbank</td>\n",
       "      <td>Без оценки по причине, что так и допожно быть ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-03-25 00:35:00</td>\n",
       "      <td>без оценки причине что так допожно в нормальны...</td>\n",
       "      <td>1</td>\n",
       "      <td>в</td>\n",
       "      <td>без оценк причин что так допожн в нормальн бан...</td>\n",
       "      <td>0.447934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rsb</td>\n",
       "      <td>Был клиентом огромного кол-ва финансовых учреж...</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-02-09 11:32:00</td>\n",
       "      <td>клиентом огромного колва финансовых учреждений...</td>\n",
       "      <td>2</td>\n",
       "      <td>в в</td>\n",
       "      <td>клиент огромн колв финансов учрежден бизнес по...</td>\n",
       "      <td>0.722269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Вопрос:Добрый день! Я страдаю от тяжелой депре...</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-09-27 21:27:00</td>\n",
       "      <td>вопрос добрый день восклицание страдаю тяжелой...</td>\n",
       "      <td>7</td>\n",
       "      <td>а</td>\n",
       "      <td>вопрос добр ден восклицан страда тяжел депресс...</td>\n",
       "      <td>0.421834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avangard</td>\n",
       "      <td>Партнёрствую с Авангардом уже более 10 лет и к...</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-12 12:25:00</td>\n",
       "      <td>партнерствую авангардом лет как физ как юрлицо...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>партнерств авангард лет как физ как юрлиц стал...</td>\n",
       "      <td>0.447373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>modulbank</td>\n",
       "      <td>Здравствуйте,У меня строительная организация  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-27 14:50:00</td>\n",
       "      <td>здравствуйте меня строительная организация зан...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>здравств мен строительн организац занима тендо...</td>\n",
       "      <td>0.439591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>trust</td>\n",
       "      <td>Являюсь вкладчиком с весны. Тысячу раз уже пож...</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-10-14 19:08:00</td>\n",
       "      <td>являюсь вкладчиком весны тысячу раз пожалел эт...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>явля вкладчик весн тысяч раз пожалел эт питер ...</td>\n",
       "      <td>0.389042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>В субботу 08.04 я пришла в отделение банка на ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-04 14:59:00</td>\n",
       "      <td>в субботу пришла в отделение банка на комсомол...</td>\n",
       "      <td>2</td>\n",
       "      <td>в</td>\n",
       "      <td>в суббот пришл в отделен банк на комсомольск п...</td>\n",
       "      <td>0.340138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>tcs</td>\n",
       "      <td>Здравствуйте, оставил заявку на сайте на получ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-09-26 00:30:00</td>\n",
       "      <td>здравствуйте оставил заявку на сайте на получе...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>здравств остав заявк на сайт на получен кредит...</td>\n",
       "      <td>0.282219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>avangard</td>\n",
       "      <td>Несколько лет пользуюсь услугами банка, супруг...</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-05-14 11:03:00</td>\n",
       "      <td>несколько лет пользуюсь услугами банка супруга...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>нескольк лет польз услуг банк супруг тож вполн...</td>\n",
       "      <td>0.280051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               bank                                              feeds  \\\n",
       "0    homecreditbank  Несколько лет с удовольствием пользовалась усл...   \n",
       "1     unicreditbank  Без оценки по причине, что так и допожно быть ...   \n",
       "2               rsb  Был клиентом огромного кол-ва финансовых учреж...   \n",
       "3          alfabank  Вопрос:Добрый день! Я страдаю от тяжелой депре...   \n",
       "4          avangard  Партнёрствую с Авангардом уже более 10 лет и к...   \n",
       "..              ...                                                ...   \n",
       "409       modulbank  Здравствуйте,У меня строительная организация  ...   \n",
       "410           trust  Являюсь вкладчиком с весны. Тысячу раз уже пож...   \n",
       "411  v-express-bank  В субботу 08.04 я пришла в отделение банка на ...   \n",
       "412             tcs  Здравствуйте, оставил заявку на сайте на получ...   \n",
       "413        avangard  Несколько лет пользуюсь услугами банка, супруг...   \n",
       "\n",
       "     grades                 date  \\\n",
       "0         3  2015-02-10 19:29:00   \n",
       "1         5  2014-03-25 00:35:00   \n",
       "2         5  2015-02-09 11:32:00   \n",
       "3         3  2020-09-27 21:27:00   \n",
       "4         5  2018-04-12 12:25:00   \n",
       "..      ...                  ...   \n",
       "409       2  2019-07-27 14:50:00   \n",
       "410       1  2013-10-14 19:08:00   \n",
       "411       1  2017-10-04 14:59:00   \n",
       "412       2  2012-09-26 00:30:00   \n",
       "413       2  2014-05-14 11:03:00   \n",
       "\n",
       "                                            prep_feeds  cups_num cups_words  \\\n",
       "0    несколько лет удовольствием пользовалась услуг...         0        NaN   \n",
       "1    без оценки причине что так допожно в нормальны...         1          в   \n",
       "2    клиентом огромного колва финансовых учреждений...         2        в в   \n",
       "3    вопрос добрый день восклицание страдаю тяжелой...         7         а    \n",
       "4    партнерствую авангардом лет как физ как юрлицо...         2        NaN   \n",
       "..                                                 ...       ...        ...   \n",
       "409  здравствуйте меня строительная организация зан...         0        NaN   \n",
       "410  являюсь вкладчиком весны тысячу раз пожалел эт...         3        NaN   \n",
       "411  в субботу пришла в отделение банка на комсомол...         2          в   \n",
       "412  здравствуйте оставил заявку на сайте на получе...         0        NaN   \n",
       "413  несколько лет пользуюсь услугами банка супруга...         0        NaN   \n",
       "\n",
       "                                             stem_text     proba  \n",
       "0    нескольк лет удовольств пользова услуг эт банк...  0.452553  \n",
       "1    без оценк причин что так допожн в нормальн бан...  0.447934  \n",
       "2    клиент огромн колв финансов учрежден бизнес по...  0.722269  \n",
       "3    вопрос добр ден восклицан страда тяжел депресс...  0.421834  \n",
       "4    партнерств авангард лет как физ как юрлиц стал...  0.447373  \n",
       "..                                                 ...       ...  \n",
       "409  здравств мен строительн организац занима тендо...  0.439591  \n",
       "410  явля вкладчик весн тысяч раз пожалел эт питер ...  0.389042  \n",
       "411  в суббот пришл в отделен банк на комсомольск п...  0.340138  \n",
       "412  здравств остав заявк на сайт на получен кредит...  0.282219  \n",
       "413  нескольк лет польз услуг банк супруг тож вполн...  0.280051  \n",
       "\n",
       "[414 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsure.iloc[:414, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_unsure = vect_words.transform(unsure.stem_text)\n",
    "all_chars_unsure = vect_chars.transform(unsure.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем матрицу признаков TF-IDF для теста и трейна\n",
    "unsure_feats = sparse.hstack([all_words_unsure, all_chars_unsure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 75000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsure_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_unsure = unsure_feats.tocsr()[:414, :]\n",
    "test_insure = unsure_feats.tocsr()[414:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = unsure.loc[:413, ['grades']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 75000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(925, 75000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оставим только нужные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid_unsure_features = valid_unsure.tocsr()[:, (np.abs(coef) > 1e-15)]\n",
    "new_test_unsure_features = test_insure.tocsr()[:, (np.abs(coef) > 1e-15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 8728)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid_unsure_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unsure_valid = model_5_LR_CV7.predict(new_valid_unsure_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35990338164251207"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(pred_unsure_valid, y_valid, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вот и реальное качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unsure_df = unsure.iloc[:414,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unsure_df = unsure.iloc[414:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    111\n",
       "3    107\n",
       "4     76\n",
       "2     65\n",
       "1     55\n",
       "Name: grades, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unsure_df.grades.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель на этих данных\n",
    "model_6_unsure_LR_CV3 = LogisticRegressionCV(solver='saga', cv=5, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, scoring=&#x27;f1_micro&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, scoring=&#x27;f1_micro&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, scoring='f1_micro', solver='saga')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_unsure_LR_CV3.fit(valid_unsure, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6521739130434783"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_unsure_valid = model_6_unsure_LR_CV3.predict(valid_unsure)\n",
    "\n",
    "f1_score(pred_unsure_valid, y_valid, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_unsure = model_6_unsure_LR_CV3.predict(test_insure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-cf8d11e8c812>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_unsure_df['new_grades'] = pred_test_unsure\n"
     ]
    }
   ],
   "source": [
    "test_unsure_df['new_grades'] = pred_test_unsure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unsure_df.to_excel('Неуверенные прогнозы на трейне/test_unsure_pred.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем разбить данные подругому"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('prep_test.csv')\n",
    "train_df = pd.read_csv('prep_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = pd.read_csv('train_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en = pd.read_csv('test_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello! I have already left a review about your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am writing to you with a complaint about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have a consumer loan taken from Svyaz-Bank a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0  I have been a client of this bank for many yea...\n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...\n",
       "2  Hello! I have already left a review about your...\n",
       "3  I am writing to you with a complaint about the...\n",
       "4  I have a consumer loan taken from Svyaz-Bank a..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['en'] = train_en.comment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['en'] = test_en.comment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "      <td>Hello! I have already left a review about your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "      <td>I am writing to you with a complaint about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>I have a consumer loan taken from Svyaz-Bank a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank                                              feeds  grades  \\\n",
       "0           ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1    fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "2       alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     NaN   \n",
       "3            vtb  Обращаюсь к Вам с жалобой на незаконное списан...     NaN   \n",
       "4  promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2  2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3  2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "4  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         7       отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                            г  в ао   \n",
       "2         4                                      в но  а  фио    \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...   \n",
       "4         4                                            в в псб   \n",
       "\n",
       "                                                  en  \n",
       "0  I have been a client of this bank for many yea...  \n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...  \n",
       "2  Hello! I have already left a review about your...  \n",
       "3  I am writing to you with a complaint about the...  \n",
       "4  I have a consumer loan taken from Svyaz-Bank a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>01.07.2020 10:53</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We arrange a mortgage in Sberbank. On 06/22/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>20.06.2019 13:19</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>Short content: I do not recommend taking a loa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>20.02.2016 11:46</td>\n",
       "      <td>добрый день уважаемые сотрудники службы контро...</td>\n",
       "      <td>3</td>\n",
       "      <td>м   цб</td>\n",
       "      <td>Good afternoon, dear employees of the quality ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>06.05.2019 15:48</td>\n",
       "      <td>обращался получением карты зеленая польза сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I applied for a \"Green Benefit\" card, the empl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>23.05.2016 15:41</td>\n",
       "      <td>обратилась в отделение банка на проспекте лени...</td>\n",
       "      <td>9</td>\n",
       "      <td>втб    втб   втб   бесплатно колоссальный боль...</td>\n",
       "      <td>On May 20, 2016, she applied to the bank branc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "               date                                         prep_feeds  \\\n",
       "0  01.07.2020 10:53  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1  20.06.2019 13:19  краткое содержание не рекомендую брать кредит ...   \n",
       "2  20.02.2016 11:46  добрый день уважаемые сотрудники службы контро...   \n",
       "3  06.05.2019 15:48  обращался получением карты зеленая польза сотр...   \n",
       "4  23.05.2016 15:41  обратилась в отделение банка на проспекте лени...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         0                                                NaN   \n",
       "1         3                                              в в в   \n",
       "2         3                                             м   цб   \n",
       "3         0                                                NaN   \n",
       "4         9  втб    втб   втб   бесплатно колоссальный боль...   \n",
       "\n",
       "                                                  en  \n",
       "0  We arrange a mortgage in Sberbank. On 06/22/20...  \n",
       "1  Short content: I do not recommend taking a loa...  \n",
       "2  Good afternoon, dear employees of the quality ...  \n",
       "3  I applied for a \"Green Benefit\" card, the empl...  \n",
       "4  On May 20, 2016, she applied to the bank branc...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_notna = train_df[train_df.grades.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    27739\n",
       "5.0    14227\n",
       "2.0     5634\n",
       "3.0     2356\n",
       "4.0     1520\n",
       "Name: grades, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_notna.grades.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработаем и обучим модель на английском\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have been a client of this bank for many years, but the last visit just left a negative in my soul! As a bank client, I was offered a credit card, after thinking about the offer, I decided to issue it. 09.02 I went to the office at Yekaterinburg, b. Ak. Bardina, 17, filled out an application, they said to wait 15 minutes, after approval came to draw up. The specialist who worked with me said that I needed to pay 900 rubles for servicing the card, I asked her why they didn’t warn me in advance, to which she smiled at me with a smirk. HORRIBLE CUSTOMER TREATMENT! It gets even worse ((After specifying how long the approval for the application is valid (10 days), we agreed that I would come on another day! On 13.02 I come to the bank, the same employee cannot print the contract, smiling, she says to me: OH, what- then the loan doesn’t want to be approved for you?! (Let’s fill out a new application for you on general terms, in general, there is a refusal ((Chuckling, she told me to wait for a new offer, without even apologizing ((HORROR! Where do you find them? Employees in front of clients they discuss each other, their personal problems, it's just disgusting! A very negative impression was left after visiting this office and resentment towards themselves! I don’t think that such employees have a place in your bank, you can generally be left without clients with them!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_notna.en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[A-z]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('english') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75000it [02:22, 525.22it/s]\n"
     ]
    }
   ],
   "source": [
    "lemmas = []\n",
    "for i, text in tqdm(enumerate(train_df['en'].tolist())):\n",
    "    lemmas.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17220it [00:32, 527.67it/s]\n"
     ]
    }
   ],
   "source": [
    "lemmas = []\n",
    "for i, text in tqdm(enumerate(test_df['en'].tolist())):\n",
    "    lemmas.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_prep_en.csv', index=False)\n",
    "test_df.to_csv('test_prep_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/51476 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#with Pool(4) as p:\n",
    "#    lemmas = list(tqdm(p.imap(clean_text, train_notna['en']), total=len(train_notna)))\n",
    "    \n",
    "#train_notna['lemmas'] = lemmas\n",
    "#train_notna.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = train_df[train_df.grades.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=250000, analyzer='word', ngram_range=(1, 3))\n",
    "vect_chars = TfidfVectorizer(max_features=12000, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_train = vect_words.fit_transform(train_notna.lemmas)\n",
    "all_chars_train = vect_chars.fit_transform(train_notna.lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 250000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 11291)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_test = vect_words.transform(test_df.lemmas)\n",
    "all_chars_test = vect_chars.transform(test_df.lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_miss = vect_words.transform(miss.lemmas)\n",
    "all_chars_miss = vect_chars.transform(miss.lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_feats = sparse.hstack([all_words_miss, all_chars_miss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем матрицу признаков TF-IDF для теста и трейна\n",
    "train_feats = sparse.hstack([all_words_train, all_chars_train])\n",
    "test_feats = sparse.hstack([all_words_test, all_chars_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель на этих данных\n",
    "model_7_en_LR_CV5 = LogisticRegressionCV(solver='saga', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kulak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, solver='saga')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_en_LR_CV5.fit(train_feats, train_notna.grades.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9168544564457223"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train_en = model_7_en_LR_CV5.predict(train_feats)\n",
    "\n",
    "f1_score(pred_train_en, train_notna.grades.values, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраним предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним модельку\n",
    "# tf-idf word250k+char12k\n",
    "with open('model_7_en.pickle', 'wb') as f:\n",
    "    pickle.dump(model_7_en_LR_CV5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем прогноз\n",
    "pred_test = model_7_en_LR_CV5.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pred_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = pd.DataFrame({'inds': test_df.index,\n",
    "                    'grades': pred_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inds</th>\n",
       "      <th>grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inds  grades\n",
       "0     0       1\n",
       "1     1       1\n",
       "2     2       1\n",
       "3     3       1\n",
       "4     4       1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.to_csv('solution_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем прогноз на пропусках\n",
    "pred_miss = model_7_en_LR_CV5.predict(miss_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_miss_prob = model_7_en_LR_CV5.predict_proba(miss_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-2cfa22ab6d4a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  miss.grades = pred_miss\n"
     ]
    }
   ],
   "source": [
    "miss.grades = pred_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = pred_miss_prob.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-99-f844556b3274>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  miss['prob'] = probs\n"
     ]
    }
   ],
   "source": [
    "miss['prob'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "      <td>Hello! I have already left a review about your...</td>\n",
       "      <td>hello already left review bank incompetence em...</td>\n",
       "      <td>0.841549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "      <td>I am writing to you with a complaint about the...</td>\n",
       "      <td>writing complaint illegal debiting funds child...</td>\n",
       "      <td>0.976208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pochtabank</td>\n",
       "      <td>Брала кредит на стиральную машину. Все платила...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-09-04 17:19:00</td>\n",
       "      <td>брала кредит на стиральную машину платила в ср...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I took out a loan for a washing machine. Every...</td>\n",
       "      <td>took loan washing machine everything paid time...</td>\n",
       "      <td>0.794737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>otpbank</td>\n",
       "      <td>Откуда взялся долг по кредитной карте, если я ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-28 13:20:00</td>\n",
       "      <td>откуда взялся долг кредитной карте карту никог...</td>\n",
       "      <td>3</td>\n",
       "      <td>ооо</td>\n",
       "      <td>Where did the credit card debt come from if I ...</td>\n",
       "      <td>credit card debt come never issued card bank l...</td>\n",
       "      <td>0.910927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Уважаемый Бинбанк, если у вас имеются какие-ли...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-08-31 16:48:00</td>\n",
       "      <td>уважаемый бинбанк вас имеются какиелибо вопрос...</td>\n",
       "      <td>1</td>\n",
       "      <td>кк</td>\n",
       "      <td>Dear Binbank, if you have any questions, pleas...</td>\n",
       "      <td>dear binbank questions please contact phone nu...</td>\n",
       "      <td>0.936102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "2     alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     1.0   \n",
       "3          vtb  Обращаюсь к Вам с жалобой на незаконное списан...     1.0   \n",
       "5   pochtabank  Брала кредит на стиральную машину. Все платила...     1.0   \n",
       "6      otpbank  Откуда взялся долг по кредитной карте, если я ...     1.0   \n",
       "9  fk_otkritie  Уважаемый Бинбанк, если у вас имеются какие-ли...     1.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "2  2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3  2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "5  2015-09-04 17:19:00  брала кредит на стиральную машину платила в ср...   \n",
       "6  2021-01-28 13:20:00  откуда взялся долг кредитной карте карту никог...   \n",
       "9  2018-08-31 16:48:00  уважаемый бинбанк вас имеются какиелибо вопрос...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "2         4                                      в но  а  фио    \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...   \n",
       "5         2                                                NaN   \n",
       "6         3                                                ооо   \n",
       "9         1                                                кк    \n",
       "\n",
       "                                                  en  \\\n",
       "2  Hello! I have already left a review about your...   \n",
       "3  I am writing to you with a complaint about the...   \n",
       "5  I took out a loan for a washing machine. Every...   \n",
       "6  Where did the credit card debt come from if I ...   \n",
       "9  Dear Binbank, if you have any questions, pleas...   \n",
       "\n",
       "                                              lemmas      prob  \n",
       "2  hello already left review bank incompetence em...  0.841549  \n",
       "3  writing complaint illegal debiting funds child...  0.976208  \n",
       "5  took loan washing machine everything paid time...  0.794737  \n",
       "6  credit card debt come never issued card bank l...  0.910927  \n",
       "9  dear binbank questions please contact phone nu...  0.936102  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss.to_csv('train_en_w_miss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = miss[((miss.grades == 1)&(miss.prob>0.5))|((miss.grades != 1)&(miss.prob>0.7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_add_en = pd.concat([train_notna, add], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_add_en.drop(columns=['prob'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_add_en.to_csv('train_en_w_miss.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем посмотреть на окончания цитат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "      <td>client bank many years last visit left negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "      <td>rostov lenina december single competent employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>I have a consumer loan taken from Svyaz-Bank a...</td>\n",
       "      <td>consumer loan taken svyaz bank transferred pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Хочу выразить глубокую благодарность всем сотр...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-04-19 20:11:00</td>\n",
       "      <td>хочу выразить глубокую благодарность всем сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I want to express my deep gratitude to all emp...</td>\n",
       "      <td>want express deep gratitude employees high lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vtb</td>\n",
       "      <td>6 марта 2019г. В 10:33 при проходе в метро \"Ку...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-03-28 18:36:00</td>\n",
       "      <td>марта в проходе в метро курская социальной кар...</td>\n",
       "      <td>3</td>\n",
       "      <td>в втб</td>\n",
       "      <td>March 6, 2019 At 10:33 when I was going to the...</td>\n",
       "      <td>march going metro station kurskaya social card...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  grades  \\\n",
       "0            ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1     fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "4   promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "7  homecreditbank  Хочу выразить глубокую благодарность всем сотр...     5.0   \n",
       "8             vtb  6 марта 2019г. В 10:33 при проходе в метро \"Ку...     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "4  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "7  2015-04-19 20:11:00  хочу выразить глубокую благодарность всем сотр...   \n",
       "8  2019-03-28 18:36:00  марта в проходе в метро курская социальной кар...   \n",
       "\n",
       "   cups_num                                    cups_words  \\\n",
       "0         7  отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                       г  в ао   \n",
       "4         4                                       в в псб   \n",
       "7         0                                           NaN   \n",
       "8         3                                         в втб   \n",
       "\n",
       "                                                  en  \\\n",
       "0  I have been a client of this bank for many yea...   \n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...   \n",
       "4  I have a consumer loan taken from Svyaz-Bank a...   \n",
       "7  I want to express my deep gratitude to all emp...   \n",
       "8  March 6, 2019 At 10:33 when I was going to the...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  client bank many years last visit left negativ...  \n",
       "1  rostov lenina december single competent employ...  \n",
       "4  consumer loan taken svyaz bank transferred pro...  \n",
       "7  want express deep gratitude employees high lev...  \n",
       "8  march going metro station kurskaya social card...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= 'Эксперимент 2/prep_train.csv'\n",
    "path2 = 'Эксперимент 2/train_prep_en.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tr = pd.read_csv(path1)\n",
    "df2_tr = pd.read_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank                                              feeds  grades  \\\n",
       "0           ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1    fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "2       alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     NaN   \n",
       "3            vtb  Обращаюсь к Вам с жалобой на незаконное списан...     NaN   \n",
       "4  promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2  2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3  2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "4  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "\n",
       "   cups_num                                         cups_words  \n",
       "0         7       отвратительное отношение клиентам  ой  ужас   \n",
       "1         3                                            г  в ао  \n",
       "2         4                                      в но  а  фио   \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...  \n",
       "4         4                                            в в псб  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "      <td>client bank many years last visit left negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "      <td>rostov lenina december single competent employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "      <td>Hello! I have already left a review about your...</td>\n",
       "      <td>hello already left review bank incompetence em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "      <td>I am writing to you with a complaint about the...</td>\n",
       "      <td>writing complaint illegal debiting funds child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>I have a consumer loan taken from Svyaz-Bank a...</td>\n",
       "      <td>consumer loan taken svyaz bank transferred pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank                                              feeds  grades  \\\n",
       "0           ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1    fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "2       alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     NaN   \n",
       "3            vtb  Обращаюсь к Вам с жалобой на незаконное списан...     NaN   \n",
       "4  promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2  2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3  2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "4  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         7       отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                            г  в ао   \n",
       "2         4                                      в но  а  фио    \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...   \n",
       "4         4                                            в в псб   \n",
       "\n",
       "                                                  en  \\\n",
       "0  I have been a client of this bank for many yea...   \n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...   \n",
       "2  Hello! I have already left a review about your...   \n",
       "3  I am writing to you with a complaint about the...   \n",
       "4  I have a consumer loan taken from Svyaz-Bank a...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  client bank many years last visit left negativ...  \n",
       "1  rostov lenina december single competent employ...  \n",
       "2  hello already left review bank incompetence em...  \n",
       "3  writing complaint illegal debiting funds child...  \n",
       "4  consumer loan taken svyaz bank transferred pro...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path11= 'Эксперимент 2/prep_test.csv'\n",
    "path22 = 'Эксперимент 2/test_prep_en.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test = pd.read_csv(path11)\n",
    "df2_test = pd.read_csv(path22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>01.07.2020 10:53</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>20.06.2019 13:19</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>20.02.2016 11:46</td>\n",
       "      <td>добрый день уважаемые сотрудники службы контро...</td>\n",
       "      <td>3</td>\n",
       "      <td>м   цб</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>06.05.2019 15:48</td>\n",
       "      <td>обращался получением карты зеленая польза сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>23.05.2016 15:41</td>\n",
       "      <td>обратилась в отделение банка на проспекте лени...</td>\n",
       "      <td>9</td>\n",
       "      <td>втб    втб   втб   бесплатно колоссальный боль...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "               date                                         prep_feeds  \\\n",
       "0  01.07.2020 10:53  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1  20.06.2019 13:19  краткое содержание не рекомендую брать кредит ...   \n",
       "2  20.02.2016 11:46  добрый день уважаемые сотрудники службы контро...   \n",
       "3  06.05.2019 15:48  обращался получением карты зеленая польза сотр...   \n",
       "4  23.05.2016 15:41  обратилась в отделение банка на проспекте лени...   \n",
       "\n",
       "   cups_num                                         cups_words  \n",
       "0         0                                                NaN  \n",
       "1         3                                              в в в  \n",
       "2         3                                             м   цб  \n",
       "3         0                                                NaN  \n",
       "4         9  втб    втб   втб   бесплатно колоссальный боль...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>01.07.2020 10:53</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We arrange a mortgage in Sberbank. On 06/22/20...</td>\n",
       "      <td>arrange mortgage sberbank necessary documents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>20.06.2019 13:19</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>Short content: I do not recommend taking a loa...</td>\n",
       "      <td>short content recommend taking loan bank clien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>Добрый день, уважаемые сотрудники службы контр...</td>\n",
       "      <td>20.02.2016 11:46</td>\n",
       "      <td>добрый день уважаемые сотрудники службы контро...</td>\n",
       "      <td>3</td>\n",
       "      <td>м   цб</td>\n",
       "      <td>Good afternoon, dear employees of the quality ...</td>\n",
       "      <td>good afternoon dear employees quality control ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>Обращался за получением карты \"Зеленая польза\"...</td>\n",
       "      <td>06.05.2019 15:48</td>\n",
       "      <td>обращался получением карты зеленая польза сотр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I applied for a \"Green Benefit\" card, the empl...</td>\n",
       "      <td>applied green benefit card employees said inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>20.05.2016 обратилась в отделение банка на про...</td>\n",
       "      <td>23.05.2016 15:41</td>\n",
       "      <td>обратилась в отделение банка на проспекте лени...</td>\n",
       "      <td>9</td>\n",
       "      <td>втб    втб   втб   бесплатно колоссальный боль...</td>\n",
       "      <td>On May 20, 2016, she applied to the bank branc...</td>\n",
       "      <td>applied bank branch lenina prospekt mortgage c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank                                              feeds  \\\n",
       "0        sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1        alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "2  v-express-bank  Добрый день, уважаемые сотрудники службы контр...   \n",
       "3  homecreditbank  Обращался за получением карты \"Зеленая польза\"...   \n",
       "4             vtb  20.05.2016 обратилась в отделение банка на про...   \n",
       "\n",
       "               date                                         prep_feeds  \\\n",
       "0  01.07.2020 10:53  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1  20.06.2019 13:19  краткое содержание не рекомендую брать кредит ...   \n",
       "2  20.02.2016 11:46  добрый день уважаемые сотрудники службы контро...   \n",
       "3  06.05.2019 15:48  обращался получением карты зеленая польза сотр...   \n",
       "4  23.05.2016 15:41  обратилась в отделение банка на проспекте лени...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         0                                                NaN   \n",
       "1         3                                              в в в   \n",
       "2         3                                             м   цб   \n",
       "3         0                                                NaN   \n",
       "4         9  втб    втб   втб   бесплатно колоссальный боль...   \n",
       "\n",
       "                                                  en  \\\n",
       "0  We arrange a mortgage in Sberbank. On 06/22/20...   \n",
       "1  Short content: I do not recommend taking a loa...   \n",
       "2  Good afternoon, dear employees of the quality ...   \n",
       "3  I applied for a \"Green Benefit\" card, the empl...   \n",
       "4  On May 20, 2016, she applied to the bank branc...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  arrange mortgage sberbank necessary documents ...  \n",
       "1  short content recommend taking loan bank clien...  \n",
       "2  good afternoon dear employees quality control ...  \n",
       "3  applied green benefit card employees said inst...  \n",
       "4  applied bank branch lenina prospekt mortgage c...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приготовим данные и обучим модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tr.date = pd.to_datetime(df1_tr.date)\n",
    "df1_tr['y'] = df1_tr.date.dt.year\n",
    "df1_tr['m'] = df1_tr.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tr.date = pd.to_datetime(df2_tr.date)\n",
    "df2_tr['y'] = df2_tr.date.dt.year\n",
    "df2_tr['m'] = df2_tr.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test.date = pd.to_datetime(df1_test.date)\n",
    "df1_test['y'] = df1_test.date.dt.year\n",
    "df1_test['m'] = df1_test.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_test.date = pd.to_datetime(df2_test.date)\n",
    "df2_test['y'] = df2_test.date.dt.year\n",
    "df2_test['m'] = df2_test.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks = df1_tr.bank.value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df1_tr.y.value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bank_rating(banks, years):\n",
    "    means = {}\n",
    "    for b in banks:\n",
    "        means[b] = {}\n",
    "        for y in years:\n",
    "            means[b][y] = df1_tr[(df1_tr.bank == b) & (df1_tr.y == y)].grades.mean()\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рейтинг банков по годам\n",
    "b_rating = bank_rating(banks, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rating = df1_tr.grades.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.395096744113762"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75000it [00:03, 23108.30it/s]\n"
     ]
    }
   ],
   "source": [
    "rating = []\n",
    "for i, item in tqdm(enumerate(df1_tr.iterrows())):\n",
    "    tmp = b_rating.get(item[1][0], {})\n",
    "    res = tmp.get(item[1][-2], mean_rating)\n",
    "    rating.append(res)\n",
    "    #if i == 6: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tr['rating'] = rating\n",
    "df2_tr['rating'] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим длину коментов\n",
    "df1_tr['len'] = df1_tr.feeds.apply(lambda x: len(x))\n",
    "df2_tr['len'] = df2_tr.feeds.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bank                                              feeds  grades  \\\n",
       "0  ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "\n",
       "   cups_num                                    cups_words     y  m  rating  \\\n",
       "0         7  отвратительное отношение клиентам  ой  ужас   2017  2     2.0   \n",
       "\n",
       "    len  \n",
       "0  1286  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tr.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17220it [00:01, 15003.16it/s]\n"
     ]
    }
   ],
   "source": [
    "rating = []\n",
    "for i, item in tqdm(enumerate(df1_test.iterrows())):\n",
    "    tmp = b_rating.get(item[1][0], {})\n",
    "    res = tmp.get(item[1][-2], mean_rating)\n",
    "    rating.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test['rating'] = rating\n",
    "df2_test['rating'] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим длину коментов\n",
    "df1_test['len'] = df1_test.feeds.apply(lambda x: len(x))\n",
    "df2_test['len'] = df2_test.feeds.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>2020-01-07 10:53:00</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1.938999</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>2019-06-20 13:19:00</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bank                                              feeds  \\\n",
       "0  sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1  alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2020-01-07 10:53:00  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1 2019-06-20 13:19:00  краткое содержание не рекомендую брать кредит ...   \n",
       "\n",
       "   cups_num cups_words     y  m    rating   len  \n",
       "0         0        NaN  2020  1  1.938999   331  \n",
       "1         3      в в в  2019  6  2.174785  1048  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сделаем лемматизацию для 1 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>1.940767</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>2.038381</td>\n",
       "      <td>2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>2.088083</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank                                              feeds  grades  \\\n",
       "0           ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1    fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "2       alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     NaN   \n",
       "3            vtb  Обращаюсь к Вам с жалобой на незаконное списан...     NaN   \n",
       "4  promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1 2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2 2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3 2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "4 2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "\n",
       "   cups_num                                         cups_words     y   m  \\\n",
       "0         7       отвратительное отношение клиентам  ой  ужас   2017   2   \n",
       "1         3                                            г  в ао  2016  12   \n",
       "2         4                                      в но  а  фио   2019   6   \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...  2020   7   \n",
       "4         4                                            в в псб  2020   4   \n",
       "\n",
       "     rating   len  \n",
       "0  2.000000  1286  \n",
       "1  1.940767  1000  \n",
       "2  2.174785  1155  \n",
       "3  2.038381  2117  \n",
       "4  2.088083  1614  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[А-Яа-яA-z]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75000it [21:30, 58.11it/s]\n"
     ]
    }
   ],
   "source": [
    "lemmas = []\n",
    "for i, text in tqdm(enumerate(df1_tr['prep_feeds'].tolist())):\n",
    "    lemmas.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tr['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17220it [04:59, 57.52it/s]\n"
     ]
    }
   ],
   "source": [
    "lemmas = []\n",
    "for i, text in tqdm(enumerate(df1_test['prep_feeds'].tolist())):\n",
    "    lemmas.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сделаем предикт на английских текстах и на русских"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=250000, analyzer='word', ngram_range=(1, 3))\n",
    "vect_chars = TfidfVectorizer(max_features=12000, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_train = vect_words.fit_transform(df2_tr[df2_tr.grades.notna()].lemmas)\n",
    "all_chars_train = vect_chars.fit_transform(df2_tr[df2_tr.grades.notna()].lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 250000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 11291)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_miss = vect_words.transform(df2_tr[df2_tr.grades.isna()].lemmas)\n",
    "all_chars_miss = vect_chars.transform(df2_tr[df2_tr.grades.isna()].lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_test = vect_words.transform(df2_test.lemmas)\n",
    "all_chars_test = vect_chars.transform(df2_test.lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем матрицу признаков TF-IDF для теста и трейна\n",
    "train_feats = sparse.hstack([all_words_train, all_chars_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_feats = sparse.hstack([all_words_miss, all_chars_miss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = sparse.hstack([all_words_test, all_chars_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим модель и сделаем предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим модельку\n",
    "# tf-idf word250k+char12k\n",
    "with open('model_7_en.pickle', 'rb') as f:\n",
    "    model_7_en_LR_CV5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем прогноз на пропусках\n",
    "pred_miss_en = model_7_en_LR_CV5.predict(miss_feats)\n",
    "pred_miss_prob_en = model_7_en_LR_CV5.predict_proba(miss_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_en = model_7_en_LR_CV5.predict(train_feats)\n",
    "pred_train_prob_en = model_7_en_LR_CV5.predict_proba(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_en = model_7_en_LR_CV5.predict(test_feats)\n",
    "pred_test_en_prob = model_7_en_LR_CV5.predict_proba(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tr['predict'] = 1\n",
    "df2_tr['predict_prob'] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "df2_tr.loc[df2_tr[df2_tr.grades.notna()].index, ['predict']] = pred_train_en\n",
    "df2_tr.loc[df2_tr[df2_tr.grades.notna()].index, ['predict_prob']] = pred_train_prob_en.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miss\n",
    "df2_tr.loc[df2_tr[df2_tr.grades.isna()].index, ['predict']] = pred_miss_en\n",
    "df2_tr.loc[df2_tr[df2_tr.grades.isna()].index, ['predict_prob']] = pred_miss_prob_en.max(axis=1)\n",
    "df2_tr.loc[df2_tr[df2_tr.grades.isna()].index, ['grades']] = pred_miss_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df2_test['predict'] = pred_test_en\n",
    "df2_test['predict_prob'] = pred_test_en_prob.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "      <td>client bank many years last visit left negativ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "      <td>rostov lenina december single competent employ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>1.940767</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "0         ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1  fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1 2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "\n",
       "   cups_num                                    cups_words  \\\n",
       "0         7  отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                       г  в ао   \n",
       "\n",
       "                                                  en  \\\n",
       "0  I have been a client of this bank for many yea...   \n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...   \n",
       "\n",
       "                                              lemmas     y   m    rating  \\\n",
       "0  client bank many years last visit left negativ...  2017   2  2.000000   \n",
       "1  rostov lenina december single competent employ...  2016  12  1.940767   \n",
       "\n",
       "    len  predict  predict_prob  \n",
       "0  1286        1      0.932908  \n",
       "1  1000        2      0.570063  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_tr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь русскую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_rt = pd.read_csv(\"Эксперимент 2/stem_prep_train.csv\")\n",
    "stem_test = pd.read_csv(\"Эксперимент 2/stem_prep_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>лет явля клиент эт банк но последн виз прост о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>ростовнадон ул ленин час в дан офис не оказа н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Здравствуйте!Ранее уже оставлял отзыв о вашем ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-28 13:54:00</td>\n",
       "      <td>здравствуйте восклицание ранее оставлял отзыв ...</td>\n",
       "      <td>4</td>\n",
       "      <td>в но  а  фио</td>\n",
       "      <td>здравств восклицан ран оставля отз ваш банк не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>Обращаюсь к Вам с жалобой на незаконное списан...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 14:54:00</td>\n",
       "      <td>обращаюсь вам жалобой на незаконное списание д...</td>\n",
       "      <td>30</td>\n",
       "      <td>пао  втб   уфк пао  втб   пао  втб   n     фз ...</td>\n",
       "      <td>обраща вам жалоб на незакон списан денежн сред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>Имею потребительский кредит, взятый в Связь-ба...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-08 06:38:00</td>\n",
       "      <td>имею потребительский кредит взятый в связьбанк...</td>\n",
       "      <td>4</td>\n",
       "      <td>в в псб</td>\n",
       "      <td>им потребительск кред взят в связьбанк перешед...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank                                              feeds  grades  \\\n",
       "0           ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1    fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "2       alfabank  Здравствуйте!Ранее уже оставлял отзыв о вашем ...     NaN   \n",
       "3            vtb  Обращаюсь к Вам с жалобой на незаконное списан...     NaN   \n",
       "4  promsvyazbank  Имею потребительский кредит, взятый в Связь-ба...     2.0   \n",
       "\n",
       "                  date                                         prep_feeds  \\\n",
       "0  2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1  2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "2  2019-06-28 13:54:00  здравствуйте восклицание ранее оставлял отзыв ...   \n",
       "3  2020-07-15 14:54:00  обращаюсь вам жалобой на незаконное списание д...   \n",
       "4  2020-04-08 06:38:00  имею потребительский кредит взятый в связьбанк...   \n",
       "\n",
       "   cups_num                                         cups_words  \\\n",
       "0         7       отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                            г  в ао   \n",
       "2         4                                      в но  а  фио    \n",
       "3        30  пао  втб   уфк пао  втб   пао  втб   n     фз ...   \n",
       "4         4                                            в в псб   \n",
       "\n",
       "                                           stem_text  \n",
       "0  лет явля клиент эт банк но последн виз прост о...  \n",
       "1  ростовнадон ул ленин час в дан офис не оказа н...  \n",
       "2  здравств восклицан ран оставля отз ваш банк не...  \n",
       "3  обраща вам жалоб на незакон списан денежн сред...  \n",
       "4  им потребительск кред взят в связьбанк перешед...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_rt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=50000, analyzer='word', ngram_range=(1, 3))\n",
    "vect_chars = TfidfVectorizer(max_features=25000, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_train = vect_words.fit_transform(stem_rt.stem_text)\n",
    "all_chars_train = vect_chars.fit_transform(stem_rt.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51476, 50000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_words_miss = vect_words.transform(stem_rt[stem_rt.grades.isna()].stem_text)\n",
    "#all_chars_miss = vect_chars.transform(stem_rt[stem_rt.grades.isna()].stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_test = vect_words.transform(stem_test.stem_text)\n",
    "all_chars_test = vect_chars.transform(stem_test.stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 50000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем матрицу признаков TF-IDF для теста и трейна\n",
    "train_feats_ru = sparse.hstack([all_words_train, all_chars_train])\n",
    "#train_miss_ru = sparse.hstack([all_words_miss, all_chars_miss])\n",
    "test_feats_ru = sparse.hstack([all_words_test, all_chars_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tfidf_BigData_3.pickle', 'rb') as f:\n",
    "    model_3_LR_CV3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем прогноз на пропусках\n",
    "#pred_miss_ru = model_3_LR_CV3.predict(train_miss_ru)\n",
    "#pred_miss_prob_ru = model_3_LR_CV3.predict_proba(train_miss_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_ru = model_3_LR_CV3.predict(train_feats_ru)\n",
    "pred_train_prob_ru = model_3_LR_CV3.predict_proba(train_feats_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_ru = model_3_LR_CV3.predict(test_feats_ru)\n",
    "pred_test_ru_prob = model_3_LR_CV3.predict_proba(test_feats_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_tr['predict'] = 1\n",
    "#df1_tr['predict_prob'] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "df1_tr['predict'] = pred_train_ru\n",
    "df1_tr['predict_prob'] = pred_train_prob_ru.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miss\n",
    "#df2_tr.loc[df2_tr[df2_tr.grades.isna()].index, ['predict']] = pred_miss_en\n",
    "#df2_tr.loc[df2_tr[df2_tr.grades.isna()].index, ['predict_prob']] = pred_miss_prob_en.max(axis=1)\n",
    "df1_tr.loc[df1_tr[df1_tr.grades.isna()].index, ['grades']] = pred_miss_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df1_test['predict'] = pred_test_ru\n",
    "df1_test['predict_prob'] = pred_test_ru_prob.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим что мы имеем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(stem_rt)\n",
    "del(stem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1286</td>\n",
       "      <td>являться клиент банк последний визит просто ос...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>1.940767</td>\n",
       "      <td>1000</td>\n",
       "      <td>ростовнадон ленин данный офис оказаться компет...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "0         ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1  fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1 2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "\n",
       "   cups_num                                    cups_words     y   m    rating  \\\n",
       "0         7  отвратительное отношение клиентам  ой  ужас   2017   2  2.000000   \n",
       "1         3                                       г  в ао  2016  12  1.940767   \n",
       "\n",
       "    len                                             lemmas  predict  \\\n",
       "0  1286  являться клиент банк последний визит просто ос...        1   \n",
       "1  1000  ростовнадон ленин данный офис оказаться компет...        1   \n",
       "\n",
       "   predict_prob  \n",
       "0      0.942412  \n",
       "1      0.881680  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>grades</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-02-16 16:10:00</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>7</td>\n",
       "      <td>отвратительное отношение клиентам  ой  ужас</td>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "      <td>client bank many years last visit left negativ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-12-13 01:05:00</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>3</td>\n",
       "      <td>г  в ао</td>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "      <td>rostov lenina december single competent employ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>1.940767</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bank                                              feeds  grades  \\\n",
       "0         ubrr  Много лет являюсь клиентом этого банка, но пос...     1.0   \n",
       "1  fk_otkritie  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....     2.0   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2017-02-16 16:10:00  лет являюсь клиентом этого банка но последний ...   \n",
       "1 2016-12-13 01:05:00  ростовнадону ул ленина часов в данном офисе не...   \n",
       "\n",
       "   cups_num                                    cups_words  \\\n",
       "0         7  отвратительное отношение клиентам  ой  ужас    \n",
       "1         3                                       г  в ао   \n",
       "\n",
       "                                                  en  \\\n",
       "0  I have been a client of this bank for many yea...   \n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...   \n",
       "\n",
       "                                              lemmas     y   m    rating  \\\n",
       "0  client bank many years last visit left negativ...  2017   2  2.000000   \n",
       "1  rostov lenina december single competent employ...  2016  12  1.940767   \n",
       "\n",
       "    len  predict  predict_prob  \n",
       "0  1286        1      0.932908  \n",
       "1  1000        2      0.570063  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_tr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>2020-01-07 10:53:00</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1.938999</td>\n",
       "      <td>331</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>2019-06-20 13:19:00</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bank                                              feeds  \\\n",
       "0  sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1  alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2020-01-07 10:53:00  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1 2019-06-20 13:19:00  краткое содержание не рекомендую брать кредит ...   \n",
       "\n",
       "   cups_num cups_words     y  m    rating   len  predict  predict_prob  \n",
       "0         0        NaN  2020  1  1.938999   331        1      0.959757  \n",
       "1         3      в в в  2019  6  2.174785  1048        1      0.887045  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>feeds</th>\n",
       "      <th>date</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>cups_words</th>\n",
       "      <th>en</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>2020-01-07 10:53:00</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We arrange a mortgage in Sberbank. On 06/22/20...</td>\n",
       "      <td>arrange mortgage sberbank necessary documents ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1.938999</td>\n",
       "      <td>331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>2019-06-20 13:19:00</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>3</td>\n",
       "      <td>в в в</td>\n",
       "      <td>Short content: I do not recommend taking a loa...</td>\n",
       "      <td>short content recommend taking loan bank clien...</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bank                                              feeds  \\\n",
       "0  sberbank  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1  alfabank  Краткое содержание: не рекомендую брать кредит...   \n",
       "\n",
       "                 date                                         prep_feeds  \\\n",
       "0 2020-01-07 10:53:00  оформляем ипотеку в сбербанке подгружены необх...   \n",
       "1 2019-06-20 13:19:00  краткое содержание не рекомендую брать кредит ...   \n",
       "\n",
       "   cups_num cups_words                                                 en  \\\n",
       "0         0        NaN  We arrange a mortgage in Sberbank. On 06/22/20...   \n",
       "1         3      в в в  Short content: I do not recommend taking a loa...   \n",
       "\n",
       "                                              lemmas     y  m    rating   len  \\\n",
       "0  arrange mortgage sberbank necessary documents ...  2020  1  1.938999   331   \n",
       "1  short content recommend taking loan bank clien...  2019  6  2.174785  1048   \n",
       "\n",
       "   predict  predict_prob  \n",
       "0      1.0      0.651007  \n",
       "1      1.0      0.883919  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стакнем все данные в кучу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = df1_tr.loc[:, ['bank', 'y', 'm', 'cups_num', 'rating', 'len', 'predict', 'predict_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN['predict_en'] = df2_tr.predict\n",
    "TRAIN['predict_prob_en'] = df2_tr.predict_prob\n",
    "TRAIN['grades'] = df2_tr.grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "      <th>predict_en</th>\n",
       "      <th>predict_prob_en</th>\n",
       "      <th>grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ubrr</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.940767</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570063</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1155</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935093</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841549</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtb</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>2.038381</td>\n",
       "      <td>2117</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882855</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976208</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promsvyazbank</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.088083</td>\n",
       "      <td>1614</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494922</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bank     y   m  cups_num    rating   len  predict  predict_prob  \\\n",
       "0           ubrr  2017   2         7  2.000000  1286        1      0.942412   \n",
       "1    fk_otkritie  2016  12         3  1.940767  1000        1      0.881680   \n",
       "2       alfabank  2019   6         4  2.174785  1155        1      0.935093   \n",
       "3            vtb  2020   7        30  2.038381  2117        1      0.882855   \n",
       "4  promsvyazbank  2020   4         4  2.088083  1614        1      0.798029   \n",
       "\n",
       "   predict_en  predict_prob_en  grades  \n",
       "0           1         0.932908     1.0  \n",
       "1           2         0.570063     2.0  \n",
       "2           1         0.841549     1.0  \n",
       "3           1         0.976208     1.0  \n",
       "4           1         0.494922     2.0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = df1_test.loc[:, ['bank', 'y', 'm', 'cups_num', 'rating', 'len', 'predict', 'predict_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST['predict_en'] = df2_test.predict\n",
    "TEST['predict_prob_en'] = df2_test.predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "      <th>predict_en</th>\n",
       "      <th>predict_prob_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sberbank</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.938999</td>\n",
       "      <td>331</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfabank</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v-express-bank</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.367347</td>\n",
       "      <td>731</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.816662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homecreditbank</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.877598</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtb</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2.262681</td>\n",
       "      <td>2510</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.816021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bank     y  m  cups_num    rating   len  predict  predict_prob  \\\n",
       "0        sberbank  2020  1         0  1.938999   331        1      0.959757   \n",
       "1        alfabank  2019  6         3  2.174785  1048        1      0.887045   \n",
       "2  v-express-bank  2016  2         3  1.367347   731        1      0.807355   \n",
       "3  homecreditbank  2019  6         0  2.877598   415        1      0.909200   \n",
       "4             vtb  2016  5         9  2.262681  2510        1      0.790558   \n",
       "\n",
       "   predict_en  predict_prob_en  \n",
       "0         1.0         0.651007  \n",
       "1         1.0         0.883919  \n",
       "2         1.0         0.816662  \n",
       "3         1.0         0.935203  \n",
       "4         1.0         0.816021  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 11)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17220, 10)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0, 1, 2])],   # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_train = ct.fit_transform(TRAIN.loc[:, ['bank', 'y', 'm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<75000x98 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 225000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.DataFrame(ohe_train.toarray(), index=TRAIN.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ohe = pd.concat([df_ohe, TRAIN.iloc[:, 3:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_test = ct.transform(TEST.loc[:, ['bank', 'y', 'm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe_t = pd.DataFrame(ohe_test.toarray(), index=TEST.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ohe = pd.concat([df_ohe_t, TEST.iloc[:, 3:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "      <th>predict_en</th>\n",
       "      <th>predict_prob_en</th>\n",
       "      <th>grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.940767</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570063</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...   96   97  cups_num  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0         7   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0         3   \n",
       "\n",
       "     rating   len  predict  predict_prob  predict_en  predict_prob_en  grades  \n",
       "0  2.000000  1286        1      0.942412           1         0.932908     1.0  \n",
       "1  1.940767  1000        1      0.881680           2         0.570063     2.0  \n",
       "\n",
       "[2 rows x 106 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ИТОГО ПОЛУЧИЛИ\n",
    "TRAIN_ohe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "      <th>predict_en</th>\n",
       "      <th>predict_prob_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.938999</td>\n",
       "      <td>331</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...   95   96   97  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "   cups_num    rating   len  predict  predict_prob  predict_en  \\\n",
       "0         0  1.938999   331        1      0.959757         1.0   \n",
       "1         3  2.174785  1048        1      0.887045         1.0   \n",
       "\n",
       "   predict_prob_en  \n",
       "0         0.651007  \n",
       "1         0.883919  \n",
       "\n",
       "[2 rows x 105 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_ohe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ohe.to_csv('TRAIN_ohe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ohe.to_csv('TEST_ohe.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>46 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.38.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>18 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_kulak_71hfe8</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>8 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.8 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         46 secs\n",
       "H2O_cluster_timezone:       Europe/Moscow\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.38.0.3\n",
       "H2O_cluster_version_age:    18 days\n",
       "H2O_cluster_name:           H2O_from_python_kulak_71hfe8\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    8 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.8 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# установим максимальный размер используемой оперативной памяти\n",
    "h2o.init(max_mem_size='8G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "train_aml = h2o.H2OFrame(TRAIN_ohe)\n",
    "test_aml = h2o.H2OFrame(TEST_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_aml.columns[:-1]\n",
    "y = 'grades'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |█\n",
      "17:42:51.207: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_AllModels_1_AutoML_1_20221211_174251\n",
       "\n",
       "No summary for this model</pre>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.14286128155910563\n",
       "RMSE: 0.377969947957646\n",
       "MAE: 0.12992884320011275\n",
       "RMSLE: 0.11518815444170595\n",
       "Mean Residual Deviance: 0.14286128155910563\n",
       "R^2: 0.9475998645860471\n",
       "Null degrees of freedom: 9912\n",
       "Residual degrees of freedom: 9900\n",
       "Null deviance: 27026.34115793993\n",
       "Residual deviance: 1416.183884095414\n",
       "AIC: 8870.355236238442</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.16434542981142944\n",
       "RMSE: 0.40539539934664953\n",
       "MAE: 0.13741047312810198\n",
       "RMSLE: 0.12484659945705581\n",
       "Mean Residual Deviance: 0.16434542981142944\n",
       "R^2: 0.9396216500556079\n",
       "Null degrees of freedom: 74999\n",
       "Residual degrees of freedom: 74986\n",
       "Null deviance: 204156.38525862477\n",
       "Residual deviance: 12325.907235857208\n",
       "AIC: 77436.92096196966</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>mae</td>\n",
       "<td>0.1379516</td>\n",
       "<td>0.0012550</td>\n",
       "<td>0.1391261</td>\n",
       "<td>0.1377923</td>\n",
       "<td>0.1365954</td>\n",
       "<td>0.1368979</td>\n",
       "<td>0.1393464</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>0.1645065</td>\n",
       "<td>0.0052771</td>\n",
       "<td>0.1645858</td>\n",
       "<td>0.1603754</td>\n",
       "<td>0.1588380</td>\n",
       "<td>0.1721003</td>\n",
       "<td>0.166633</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1645065</td>\n",
       "<td>0.0052771</td>\n",
       "<td>0.1645858</td>\n",
       "<td>0.1603754</td>\n",
       "<td>0.1588380</td>\n",
       "<td>0.1721003</td>\n",
       "<td>0.166633</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>40831.277</td>\n",
       "<td>327.72556</td>\n",
       "<td>40678.246</td>\n",
       "<td>40797.02</td>\n",
       "<td>40718.117</td>\n",
       "<td>41398.086</td>\n",
       "<td>40564.918</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9395657</td>\n",
       "<td>0.0014594</td>\n",
       "<td>0.9393699</td>\n",
       "<td>0.9409139</td>\n",
       "<td>0.9412000</td>\n",
       "<td>0.937938</td>\n",
       "<td>0.9384067</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>2467.3674</td>\n",
       "<td>70.15982</td>\n",
       "<td>2466.3179</td>\n",
       "<td>2410.4417</td>\n",
       "<td>2393.847</td>\n",
       "<td>2567.7356</td>\n",
       "<td>2498.495</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4055525</td>\n",
       "<td>0.0064895</td>\n",
       "<td>0.4056917</td>\n",
       "<td>0.4004689</td>\n",
       "<td>0.3985448</td>\n",
       "<td>0.4148497</td>\n",
       "<td>0.4082070</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1248019</td>\n",
       "<td>0.0011463</td>\n",
       "<td>0.1254887</td>\n",
       "<td>0.1245354</td>\n",
       "<td>0.1229466</td>\n",
       "<td>0.1258673</td>\n",
       "<td>0.1251713</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_AllModels_1_AutoML_1_20221211_174251\n",
       "\n",
       "No summary for this model\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.14286128155910563\n",
       "RMSE: 0.377969947957646\n",
       "MAE: 0.12992884320011275\n",
       "RMSLE: 0.11518815444170595\n",
       "Mean Residual Deviance: 0.14286128155910563\n",
       "R^2: 0.9475998645860471\n",
       "Null degrees of freedom: 9912\n",
       "Residual degrees of freedom: 9900\n",
       "Null deviance: 27026.34115793993\n",
       "Residual deviance: 1416.183884095414\n",
       "AIC: 8870.355236238442\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.16434542981142944\n",
       "RMSE: 0.40539539934664953\n",
       "MAE: 0.13741047312810198\n",
       "RMSLE: 0.12484659945705581\n",
       "Mean Residual Deviance: 0.16434542981142944\n",
       "R^2: 0.9396216500556079\n",
       "Null degrees of freedom: 74999\n",
       "Residual degrees of freedom: 74986\n",
       "Null deviance: 204156.38525862477\n",
       "Residual deviance: 12325.907235857208\n",
       "AIC: 77436.92096196966\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                        mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     0.137952  0.00125498  0.139126      0.137792      0.136595      0.136898      0.139346\n",
       "mean_residual_deviance  0.164506  0.00527711  0.164586      0.160375      0.158838      0.1721        0.166633\n",
       "mse                     0.164506  0.00527711  0.164586      0.160375      0.158838      0.1721        0.166633\n",
       "null_deviance           40831.3   327.726     40678.2       40797         40718.1       41398.1       40564.9\n",
       "r2                      0.939566  0.0014594   0.93937       0.940914      0.9412        0.937938      0.938407\n",
       "residual_deviance       2467.37   70.1598     2466.32       2410.44       2393.85       2567.74       2498.49\n",
       "rmse                    0.405552  0.00648948  0.405692      0.400469      0.398545      0.41485       0.408207\n",
       "rmsle                   0.124802  0.00114632  0.125489      0.124535      0.122947      0.125867      0.125171\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models=15,  \t\t# Количество различных моделей для обучения\n",
    "                seed=42, \n",
    "                max_runtime_secs = 31000)   # Максимальное время обучения одной модели\n",
    "aml.train(x=x, y=y, training_frame=train_aml)\n",
    "\n",
    "# Ждем, когда заполнится строка обучения AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train = aml.predict(train_aml).as_data_frame().values\n",
    "preds_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6505466666666667"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(preds_train.astype(int), TRAIN_ohe.grades, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "preds = aml.predict(test_aml).as_data_frame().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = pd.DataFrame({'inds': df1_test.index,\n",
    "                    'grades': preds.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9955\n",
       "4    3138\n",
       "5    1821\n",
       "0    1664\n",
       "2     599\n",
       "3      43\n",
       "Name: grades, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.grades.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.to_csv('solution_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скор на Kaggle 0.558"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = df1_tr.loc[:, ['feeds', 'prep_feeds', 'bank', 'y', 'm', 'cups_num', 'rating', 'len', 'predict', 'predict_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN['feeds_en'] = df2_tr.en\n",
    "TRAIN['lemmas_en'] = df2_tr.lemmas\n",
    "TRAIN['predict_en'] = df2_tr.predict\n",
    "TRAIN['predict_prob_en'] = df2_tr.predict_prob\n",
    "TRAIN['grades'] = df2_tr.grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = df1_test.loc[:, ['feeds', 'prep_feeds', 'bank', 'y', 'm', 'cups_num', 'rating', 'len', 'predict', 'predict_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST['feeds_en'] = df2_test.en\n",
    "TEST['lemmas_en'] = df2_test.lemmas\n",
    "TEST['predict_en'] = df2_test.predict\n",
    "TEST['predict_prob_en'] = df2_test.predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feeds</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>bank</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "      <th>feeds_en</th>\n",
       "      <th>lemmas_en</th>\n",
       "      <th>predict_en</th>\n",
       "      <th>predict_prob_en</th>\n",
       "      <th>grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Много лет являюсь клиентом этого банка, но пос...</td>\n",
       "      <td>лет являюсь клиентом этого банка но последний ...</td>\n",
       "      <td>ubrr</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942412</td>\n",
       "      <td>I have been a client of this bank for many yea...</td>\n",
       "      <td>client bank many years last visit left negativ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....</td>\n",
       "      <td>ростовнадону ул ленина часов в данном офисе не...</td>\n",
       "      <td>fk_otkritie</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1.940767</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881680</td>\n",
       "      <td>Rostov-on-Don, st. Lenina, 48. Were on Decembe...</td>\n",
       "      <td>rostov lenina december single competent employ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570063</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feeds  \\\n",
       "0  Много лет являюсь клиентом этого банка, но пос...   \n",
       "1  Г. Ростов-на-Дону, ул. Ленина, 48. Были 10.12....   \n",
       "\n",
       "                                          prep_feeds         bank     y   m  \\\n",
       "0  лет являюсь клиентом этого банка но последний ...         ubrr  2017   2   \n",
       "1  ростовнадону ул ленина часов в данном офисе не...  fk_otkritie  2016  12   \n",
       "\n",
       "   cups_num    rating   len  predict  predict_prob  \\\n",
       "0         7  2.000000  1286        1      0.942412   \n",
       "1         3  1.940767  1000        1      0.881680   \n",
       "\n",
       "                                            feeds_en  \\\n",
       "0  I have been a client of this bank for many yea...   \n",
       "1  Rostov-on-Don, st. Lenina, 48. Were on Decembe...   \n",
       "\n",
       "                                           lemmas_en  predict_en  \\\n",
       "0  client bank many years last visit left negativ...           1   \n",
       "1  rostov lenina december single competent employ...           2   \n",
       "\n",
       "   predict_prob_en  grades  \n",
       "0         0.932908     1.0  \n",
       "1         0.570063     2.0  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feeds</th>\n",
       "      <th>prep_feeds</th>\n",
       "      <th>bank</th>\n",
       "      <th>y</th>\n",
       "      <th>m</th>\n",
       "      <th>cups_num</th>\n",
       "      <th>rating</th>\n",
       "      <th>len</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_prob</th>\n",
       "      <th>feeds_en</th>\n",
       "      <th>lemmas_en</th>\n",
       "      <th>predict_en</th>\n",
       "      <th>predict_prob_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Оформляем ипотеку в Сбербанке. 22.06.2020 были...</td>\n",
       "      <td>оформляем ипотеку в сбербанке подгружены необх...</td>\n",
       "      <td>sberbank</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.938999</td>\n",
       "      <td>331</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959757</td>\n",
       "      <td>We arrange a mortgage in Sberbank. On 06/22/20...</td>\n",
       "      <td>arrange mortgage sberbank necessary documents ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Краткое содержание: не рекомендую брать кредит...</td>\n",
       "      <td>краткое содержание не рекомендую брать кредит ...</td>\n",
       "      <td>alfabank</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.174785</td>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887045</td>\n",
       "      <td>Short content: I do not recommend taking a loa...</td>\n",
       "      <td>short content recommend taking loan bank clien...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feeds  \\\n",
       "0  Оформляем ипотеку в Сбербанке. 22.06.2020 были...   \n",
       "1  Краткое содержание: не рекомендую брать кредит...   \n",
       "\n",
       "                                          prep_feeds      bank     y  m  \\\n",
       "0  оформляем ипотеку в сбербанке подгружены необх...  sberbank  2020  1   \n",
       "1  краткое содержание не рекомендую брать кредит ...  alfabank  2019  6   \n",
       "\n",
       "   cups_num    rating   len  predict  predict_prob  \\\n",
       "0         0  1.938999   331        1      0.959757   \n",
       "1         3  2.174785  1048        1      0.887045   \n",
       "\n",
       "                                            feeds_en  \\\n",
       "0  We arrange a mortgage in Sberbank. On 06/22/20...   \n",
       "1  Short content: I do not recommend taking a loa...   \n",
       "\n",
       "                                           lemmas_en  predict_en  \\\n",
       "0  arrange mortgage sberbank necessary documents ...         1.0   \n",
       "1  short content recommend taking loan bank clien...         1.0   \n",
       "\n",
       "   predict_prob_en  \n",
       "0         0.651007  \n",
       "1         0.883919  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbc = CatBoostClassifier(iterations=25000,\n",
    "                           eval_metric='MultiClass',\n",
    "                           learning_rate=0.009,\n",
    "                           custom_loss=['F1', 'TotalF1'],\n",
    "                           use_best_model=True,\n",
    "                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(TRAIN.iloc[:, :-1], TRAIN.iloc[:, -1], train_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cd77f8ce5140388f81110e0710e57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b3e2751dc0>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbc.fit(X_train, y_train,\n",
    "          verbose=False,\n",
    "          text_features=['feeds', 'prep_feeds', 'feeds_en', 'lemmas_en'],\n",
    "          cat_features=['bank', 'y', 'm', 'predict', 'predict_en'],\n",
    "          eval_set= (X_test, y_test),\n",
    "          plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST.predict_en = TEST.predict_en.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sub = model_cbc.predict(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sub = predict_sub.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = pd.DataFrame({'inds': df1_test.index,\n",
    "                    'grades': predict_sub})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inds</th>\n",
       "      <th>grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17215</th>\n",
       "      <td>17215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17216</th>\n",
       "      <td>17216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17217</th>\n",
       "      <td>17217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17218</th>\n",
       "      <td>17218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17219</th>\n",
       "      <td>17219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        inds  grades\n",
       "0          0       1\n",
       "1          1       1\n",
       "2          2       1\n",
       "3          3       1\n",
       "4          4       1\n",
       "...      ...     ...\n",
       "17215  17215       1\n",
       "17216  17216       1\n",
       "17217  17217       1\n",
       "17218  17218       1\n",
       "17219  17219       1\n",
       "\n",
       "[17220 rows x 2 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11669\n",
       "5     4952\n",
       "2      457\n",
       "3       93\n",
       "4       49\n",
       "Name: grades, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.grades.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.to_csv('solution_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скор 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
